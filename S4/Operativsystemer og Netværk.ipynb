{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Generelt \n",
    "- **Kontor** ADA-216"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual memory \n",
    "- An **operating system** from the programmers point of views adds a variety of new instructions beyond the ISA  level \n",
    "    - These instructions is called **system calls** which invokes a predefined operating system service, effectively, one of its instructions e.g. reading data from a file \n",
    "    - The Operating System Level (OSL) is always interpreted \n",
    "\n",
    "\n",
    "- **Virtual memory** is a smart way to use memory which is not available \n",
    "    - The words of memory and memory are separated so that 4096 words but they does not need to correspond to memory location 0 to 4096\n",
    "![memory_mapping](img/memory_mapping.png)\n",
    "    - If the memory is mapped between 4096 to 8191 and the program branches to memory location between 8192 and 12287 and the machine has virtual memory the following happens (**paging**)\n",
    "        1. The contents of the main memory is saved on disk\n",
    "        2. Words 8192 to 12287 would be located on disk.\n",
    "        3. Words 8192 to 12287 would be loaded into main memory.\n",
    "        4. The address map would be changed to map addresses 8192 to 12287 onto memory locations 0 to 4095.\n",
    "        5. Execution would continue as though nothing unusual had happened. \n",
    "    - The chunks of program read in from disk are called **pages**\n",
    "    - The addresses that a program refer to is called **virtual address space**\n",
    "    - The actual physical memory locations are called **physical address space** \n",
    "    - A **memory map** or **page table** specifies for each virtual address what the corresponding physical address is \n",
    "    - The paging mechanism is said to be **transparent** because the programming does not need to know that it exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "- The virtual disk space is broken up into a number of equal size pages\n",
    "    - Page sizes range from 512 to 64 KB pr page \n",
    "    - The page size is always the power of two, for example $2^k$, so that all addresses can be represented in $k$ bits\n",
    "    - The physical address space is broken into pieces in a similar way as the virtual ones\n",
    "    - The pieces of main memory into which the pages goes are called **page frames**\n",
    "        - Typically thousands exists \n",
    "        \n",
    "        \n",
    "- The device for doing virtual-to-physical mapping is called **MMU (Memory Management Unit).**\n",
    "    - may be on the CPU chip or a seperate chip\n",
    "    - To see if an page-table entry is currently in memory the MMU checks the **present/absent bit** in the page table entry\n",
    "\n",
    "\n",
    "- When a reference is made to an address on a page not present in main memory, it is called a **page fault**.\n",
    "    - After it has occurred the operating system must \n",
    "        - read the required page from disk\n",
    "        - enter its new physical memory location in the page table\n",
    "        - then repeat the instruction that caused the fault.\n",
    "    - In **demand paging**, a page is brought into memory only when a request for it occurs, not in advance.\n",
    "    - The **locality principle** is that references tend to cluster on a small number of pages.\n",
    "    - The **working set** is a set at any given time consisting of all the pages used by the k most recent memory references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page-Replacement Policy\n",
    "- When fetching a page an algorithm needs to decide which page to be sent back to disk\n",
    "    - The **LRU (Least Recently Used)** algorithm evicts the page least recently\n",
    "    - **FIFO (First-In First-Out)** removes the least recently loaded page \n",
    "    - A program that generates page faults frequently and continuously is said to be thrashing.\n",
    "    - Many operating systems has a bit which tells if the page has been written to since it was loaded \n",
    "\n",
    "\n",
    "- The problem of wasted bytes when only some of the pages are full are called **internal fragmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "- A straightforward solution to overflowing memory is to provide many completely independent address spaces, called **segments**.\n",
    "    - Each segment consists of a linear sequence of addresses, from 0 to some maximum.\n",
    "    - The length of a stack segment may be increased and decrease when the stack changes \n",
    "    - Different segments can grow and shrink independently without affecting each other\n",
    "    - It is very rare that a segment is filled up because it is very large\n",
    "    - To specify a segment the program must supply a two-part address: a segment number, and an address within the segment.\n",
    "![paging_vs_segmentation](img/paging_vs_segmentation.png)\n",
    "  \n",
    "\n",
    "- Segmentation can be implemented in one of two ways: swapping and paging \n",
    "    - Segment swapping is not unlike demand paging: segment come and and segments go as needed \n",
    "        - Implementation differs from paging because segments differs in size and paging does not\n",
    "        - **External fragmentation** is the phenomenon where after the computer has been running after some time the memory is containing segments and some containing holes\n",
    "        - **Compacting** is moving all the segments together to remove the external fragmentation\n",
    "    - Paging is dividing each segment up into fixed-size pages and demand paging them.\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads \n",
    "- A **program** can contain multiple threads\n",
    "    - Each thread has a lifetime extending from the first instruction executes to the last one\n",
    "    - If two threads has overlapping life time it is said that they are concurrent \n",
    "\n",
    "- Command to compile C program with threads: `gcc -pthread program.c -o program.out`\n",
    "\n",
    "\n",
    "- Simple multi threaded program in C\n",
    "\n",
    "```c\n",
    "#include <pthread.h>\n",
    "#include <unistd.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "static void * child(void *ignored){\n",
    "    sleep(3);\n",
    "    printf(\"Child is done sleeping 3 seconds.\\n\");\n",
    "    return NULL;\n",
    "}\n",
    "int main(int argc, char *argv[]){\n",
    "    pthread_t child_thread;\n",
    "    int code;\n",
    "    code = pthread_create(&child_thread, NULL, child, NULL);\n",
    "    if(code){\n",
    "        fprintf(stderr, \"pthread_create failed with code %d\\n\", code);\n",
    "    }\n",
    "    sleep(5);\n",
    "    printf(\"Parent is done sleeping 5 seconds.\\n\");\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Between Threads\n",
    "- To switch between different threads the processor needs to store information about that thread in memory\n",
    "    - Saves the program counter, the contents of the registers and the stack pointer for higher order languages \n",
    "    - A block of memory containing information about a thread is called a **thread control block** or **task control block** (TCB)\n",
    "\n",
    "\n",
    "- The registers can be pushed onto the stack before thread switching so thread switching is done as follows\n",
    "```\n",
    "    push each register on the (outgoing thread’s) stack\n",
    "    store the stack pointer into outgoing->SP\n",
    "    load the stack pointer from next->SP\n",
    "    store label L’s address into outgoing->IP\n",
    "    load in next->IP and jump to that address\n",
    "L:\n",
    "    pop each register from the (resumed outgoing thread’s) stack\n",
    "```\n",
    "\n",
    "- Thread switching is often called **context switching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preemptive Multitasking\n",
    "- **Cooperative multitasking** is where each thread themselves contains explicit code at each point a thread switch should occur\n",
    "- **Preemptive multitasking** is where the threads code do not contain explicit code, where the thread switch should occur \n",
    "    - It can still be useful for a thread to voluntarily give way to the other threads, normally called yield \n",
    "        - The pthreads api uses`sched_yield()`\n",
    "    - The `ret` instruction used in the Linux code for thread switching.\n",
    "- When an I/O device or timer needs attention an **interrupt** occurs and the processor jumps off to the special procedure called the **interrupt handler**\n",
    "    - Is part of the operating system and deal with the hardware device\n",
    "    - When it is done it executes a return from interrupt instruction, which jumps back to the instruction which it interrupted\n",
    "    - It needs to handler needs to save all the registers at the start and restore them before returning.\n",
    "    - Can be used by an operating system to provide preemptive multitasking.\n",
    "        - If the interrupt was from the timer and the current thread had been executing for a long time, it may be needed to switch to another thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling\n",
    "- The **scheduler** chooses which thread to run at each time \n",
    "- Checking if an desired event has occurred is called **busy waiting**\n",
    "    - Is a bad-idea\n",
    "- The operating system keeps track of which threads are waiting and which can usefully run \n",
    "    - The system does this by storing runnable threads in a **run queue** and the waiting in **waiting queues** one per reason for waiting \n",
    "        - The threads which are waiting for a desired amount of time to elapse is stored in time order\n",
    "    - The scheduler only considers threads in the run queue\n",
    "    - One of the services of the interrupt handler is do determine that a waiting thread becomes runnable \n",
    "- A thread can be in one of the following states \n",
    "    - Runnable, awaiting dispatch by the scheduler\n",
    "    - Running on a processor\n",
    "    - Waiting for some event    \n",
    "![scheduling_states](img/scheduling_states.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling goals \n",
    "- **Throughput** is the rate which useful work is accomplished.\n",
    "    - Example measure of throughput could be the number of search transactions per second \n",
    "    - Only by using all the I/O devices efficiently can a scheduler maximize throughput.\n",
    "    - Switching between threads more often than necessary will reduce throughput \n",
    "    - The thread runs best on the same processor, called **processor affinity**, because of cache therefore scheduling the same thread on the same core maximize throughput\n",
    "    - If a processor needs data from another processors cache it uses the systems **cache coherence protocol**\n",
    "        - Typically means first transferring the data from the old cache to the main memory and then transferring it from the main memory to the new cache\n",
    "        \n",
    "        \n",
    "- **Response Time** is the elapsed time from a triggering event to to a completed response \n",
    "    - A high performance system in throughput might be low performance in response time and vice versa \n",
    "    - System intended for direct interaction with a user tend to be optimized for response time whereas servers are optimized for throughput\n",
    "    - Often involves trade-offs between responding to different interactions \n",
    "        - can be done by responding to the interaction which takes the smallest amount of time to complete \n",
    "            - Called **Shortest Job First** (SJF)\n",
    "            - Normally a operating system does not know how much processor time each thread need to respond it often guess based on previous threads or based on previous burst\n",
    "            - **Burst** is the amount of processing done between waits for external events.\n",
    "        - can also be done by frequently switching between threads \n",
    "\n",
    "- A task is **urgent** if it needs to be done soon\n",
    "- **Importance** indicate how much is at stake in accomplishing a task in a timely fashion.\n",
    "- **Resource Allocation** is how the resources are allocated between task\n",
    "    - Is a matter of fairness\n",
    "    - **Proportional-share scheduling** balances the processing time given to threads over a much shorter time scale, such as a second.\n",
    "        - The idea is to focus on the runnable threads and how much time the user has allocated to them \n",
    "    - The niceness of a thread is akin to low priority. \n",
    "        - Niceness on linux is interpret of the amount of processor time\n",
    "        - Niceness on OSX is interpret as thread with high niceness only get processor time when the processor is idle\n",
    "![scheduling_goals](img/scheduling_goals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling Mechanisms \n",
    "![scheduling_mechanisms_goals](img/scheduling_mechanisms_goals.png)\n",
    "![scheduling_mechanisms](img/scheduling_mechanisms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed-Priority Scheduling\n",
    "- Threads with higher priority runs before the onces with lower priority\n",
    "- A thread cannot change priority \n",
    "- In a fixed-priority scheduler the run queue can be kept in a data-structure ordered by priority \n",
    "    - Typically represented as an array where the first entry contains a list of threads with highest priority the second entry contains a list of threads with the next highest priority, and so forth.\n",
    "    - Whenever a processor becomes idle because a thread has terminated or entered a waiting state, the scheduler dispatches a runnable thread of highest available priority.\n",
    "    - The processor also compares priorities if a thread becomes runnable \n",
    "        - If the new thread has higher priority than the running thread the scheduler performs a thread switch \n",
    "    - To deal with ties there are two possible solutions\n",
    "        - Run the thread that become runnable first until it waits for some event of voluntarily yield the processor (first in, first out (FIFO))\n",
    "        - Share the processor between the threads that are tied in a **round-robin** fashion. (RR) \n",
    "____        \n",
    "        \n",
    "- Not viable in a general purpose system \n",
    "- More suited for am environment where all the threads are part of a carefully quality-controlled system design.\n",
    "- Two key theorems make it easy to analyze a periodic hard-real-time system under fixed-priority scheduling:\n",
    "    - If the threads meet their deadlines under any fixed priority assignment, then they will do so under an assignment that prioritizes threads with shorter periods over those with longer periods. This policy is known as **rate-monotonic scheduling.**\n",
    "    - To check that the deadlines are met it suffices to check the worst cast scenario where the threads start at the same time \n",
    "___    \n",
    "    \n",
    "- To test the feasibility of a real-time schedule, it is conventional to use a **Gantt chart**.\n",
    "    - is a bar, which represent the passage of time, divided into regions labeled to show what thread is running during the corresponding  time interval.\n",
    "    - can be used to check whether a rate-monotonic fixed priority schedule will work for a given set of threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Priority Scheduling\n",
    "- In **Earliest Deadline First Scheduling** each time a thread becomes runnable the priorities according to the following rule: the sooner a threads dealing the higher its priority\n",
    "- **Decay Scheduling** priority downward from the base priority by an amount that reflects recent processor usage by that thread.\n",
    "    - The user-specified priorities can serve as base priorities, which the operating system will use as a starting point for its automatic adjustments.\n",
    "        - Most of the time the users will use the default thread priorities for all their threads and threads only differ in priority because of the \n",
    "        - The threads that are a tie after automatic adjustment are processed in a round robin fashion\n",
    "    - The time that each thread are allowed to run before switching is called a **quantum**\n",
    "        - The priority will not sink below some minimum value\n",
    "        - If the thread has been running for a while it has a low priority \n",
    "        - If the thread has not run for a long time its priority will be equal to the base priority \n",
    "    - The thread’s recent processor usage increases when the thread runs and **decays** when the thread waits\n",
    "        - The currently running thread has its usage updated whenever it voluntarily yields the processor        \n",
    "![decay_osx](img/decay_osx.png)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportional-Share Scheduling\n",
    "- When resource allocation is the primary user-goal \n",
    "- Researchers have proposed three basic mechanisms for controlling the rate at which threads are granted processor time:\n",
    "    1. Each thread can be granted the use of the processor equally often \n",
    "        - Just as in simple round robin\n",
    "        - Those who have larger allocation and granted larger time slice\n",
    "        - Known as **Weighted Round Robin Scheduling** (WRR)\n",
    "    2. A uniform time slice can be used for all threads.\n",
    "        - Those with larger allocations are run more often\n",
    "        - The smaller allocation sit out on some rotations through the list\n",
    "        - Several names are used\n",
    "            - Weighted Fair Queuing (WFQ),\n",
    "            - Stride Scheduling\n",
    "            - Virtual Time Round-Robin Scheduling (VTRR).\n",
    "    3. A uniform time slice can be used for all threads.\n",
    "        - Those with larger allocations are chosen to be run more often \n",
    "        - The threads are selected by a lottery with weighted odds\n",
    "        - This is not terribly practical\n",
    "        - Known as **lottery scheduling**\n",
    "        \n",
    "___        \n",
    "- The Linux system uses **Completely Fair Scheduler** which always run the thread which is behind on virtual runtime\n",
    "    - Virtual runtime is calculated based on the niceness of a thread and multiplied with the scale\n",
    "    - If a thread has been non-runnable for a certain amount of time its virtual runtime is set forward so as to be only slightly less than the minimum virtual runtime of any of the previously runnable threads.\n",
    "    - The run queue is kept sorted in order of the runnable threads’ virtual runtimes.\n",
    "        - Represented as a red-black search three\n",
    "    - The thread scheduler switches threads if one of the two following things happend\n",
    "        - A threads time slice has expired\n",
    "        - A new thread enters the run queue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security \n",
    "- The kind of attack most relevant to scheduling is the denial of service (DoS) attack\n",
    "    - Is an attack with the goal of preventing legitimate users of a system to be able to use it \n",
    "    - e.g. Given an urgent thread a low priority \n",
    "    - Because of systems with e.g. decay scheduling, an attacker must run many concurrent threads in order to drain off a significant fraction of the processor’s time.\n",
    "    - A limit number of threads per users will constrain denial of service attacks without causing most users much hardship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processes and Protection\n",
    "- Most mainstream systems definition of a **process** are based on definitions that include the following:\n",
    "    - **One or more threads**\n",
    "        - Is often closely associated with one thread\n",
    "        - Some programs are designed to divide work between multiple threads\n",
    "    - **Virtual memory accessible to those threads**\n",
    "        - The mainstream protection approach is for each process to have its own virtual memory address shared by threads within that process\n",
    "        - The access rights are assigned to the process, not to the individual threads.\n",
    "    - **Other access rights**\n",
    "        - The process can either hold a specific **capability** (e.g. writing to a file) or a **credential** such as the identification of the user for whom the process is running \n",
    "    - **Resource allocation context**\n",
    "        - Limited resources are associated with a process for two reasons\n",
    "            - The process’s termination may serve to implicitly release some of the resources it is holding\n",
    "            - The process may be associated with a limited resource quota\n",
    "    - **Miscellaneous context**\n",
    "        - The operating system tracks a single current working directory per process\n",
    "        - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POSIX Process Management API\n",
    "- All operating systems provide mechanisms for creating new processes, terminating existing processes, and performing related actions.\n",
    "- In the POSIX approach each process is identified by a **process ID number** which is a positive integer \n",
    "- Each process comes into existence through the forking of a parent process.\n",
    "    - Except the first process that is started when the operating system starts running \n",
    "    - A process forks off a new process whenever one of the threads running in the parent procedure calls the `fork` procedure\n",
    "    - In the parent process the call to `fork` returns returns the process ID number of the child process\n",
    "        - May be important to the parent if it want to exert some control over the child later or find out if the child terminates\n",
    "    - The child process is in many regards a copy of the parent process\n",
    "        - For protection purpose it has the same credentials as the parent \n",
    "        - The child has the the same capabilities for such purposes as access to files that have been opened for reading or writing\n",
    "        - The child contains a copy of the parents address space\n",
    "            - The operating system does not need to copy each page of address space it just copies on write (COW)\n",
    "    - The child starts by calling the `fork` procedure\n",
    "        - Fork returns a value of 0 in the child.\n",
    "        - The normal programming pattern is for any fork operation to be immediately followed by an if statement that checks the return value from fork.\n",
    "            - That way the programming code can change behavior if it is a child \n",
    "        - Failure is signaled by a negative value\n",
    "        - Used in Linux to start new programs\n",
    "\n",
    "\n",
    "- In order to wait for a child process the parent can use the `waitpid` procedure which takes three arguments\n",
    "    - The first argument is the process id of the child for which the parent should wait\n",
    "    - The two other arguments can be 0 if the parent should just wait for the just process to finish\n",
    "    - If the child process has exited before the parent the `waitpid` command does not wait\n",
    "    - The operating system retains information about the terminated process until the parent waits for it.\n",
    "    - A terminated process that has not yet been waited for is known as a zombie.\n",
    "        - Waiting for a zombie is known as reaping the zombie.\n",
    "        \n",
    "\n",
    "- A program file can have a special set user ID (`setuid`) set on it \n",
    "    - The process that executes it acquires the credential of the file’s owner.\n",
    "    - The setuid mechanism provides an extremely general mechanism for granting access rights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exec family\n",
    "- The POSIX standard includes six different procedures, any one of which can be used to load in a new program and start it running.\n",
    "    - They are commonly called the **exec family** because they have names starting with exec, \n",
    "    - Each member must be given enough information to find the new program stored in a file and to provide the program with any arguments and environment variables it needs.\n",
    "    - The family members differ in exactly how the calling program provides this information.\n",
    "    - Because the family members are so closely related, most systems define only the `execve` procedure in the kernel of the operating system itself\n",
    "    - Only return if an error occurs, because if all is well the new program starts running without the possibility of reaching the old program\n",
    "\n",
    "\n",
    "- `execl` is one of the simpler members of the exec family\n",
    "    - The first argument specifies where the program is located e.g. `/bin/ps`\n",
    "    - The remaining string are the command line arguments  e.g. `ps` and `axl`\n",
    "    - An inconvenience about `execl` is that the location of the program file is needed \n",
    "\n",
    "\n",
    "- `execlp` does not need to know the location of the program file\n",
    "    - can be given a filename and will search through the directories to find the program\n",
    "    - if used in combination with work in a program a new command can be executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronization\n",
    "- In a **race** two threads use the same data structure without any mechanisms to ensure only one threads use the data structure at a time.\n",
    "    - Can be avoided using **locks**\n",
    "- **Mutual exclusion** is when a thread temporarily excludes other threads when running on data structures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutexes and Monitors\n",
    "- A programmer can arrange for exclusive access to a data structure by using a lock object associated with it \n",
    "    - Only one thread can lock it at a time\n",
    "    - When a thread uses a lock, it **holds** the locks \n",
    "- To support race prevention, operating systems and middleware generally provide **mutual exclusion locks**\n",
    "    - Often called **Mutex** for short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mutex API \n",
    "- A mutex can be in to states locked or unlocked \n",
    "    - Needs to operations for locking and unlocking\n",
    "    - When a thread use the lock operations on a locked mutex, it waits for the lock to be unlocked \n",
    "    - If more than one thread are waiting for a mutex to be unlocked only one can unlock it and the others will wait\n",
    "    - There may also be operations for checking if a mutex is locked and removing it from memory\n",
    "\n",
    "\n",
    "- In the POSIX API `my_mutex` can be declared to be a mutex and initialize with the default attributes as follows:\n",
    "```c\n",
    "pthread_mutex_t my_mutex;\n",
    "pthread_mutex_init(&my_mutex, 0);\n",
    "```\n",
    "- A thread that wants lock a mutex, operate on the associated data structure and then unlock the mutex would do the following:\n",
    "```c\n",
    "pthread_mutex_lock(&my_mutex);\n",
    "// operate on the protected data structure\n",
    "pthread_mutex_unlock(&my_mutex);\n",
    "```\n",
    "- Destroying a mutex can be done in the following procedure call \n",
    "```c\n",
    "pthread_mutex_destroy(&my_mutex);\n",
    "```\n",
    "- POSIX has a couple variants on `pthread_mutex_lock` which can be useful under particular circumstances\n",
    "    - `pthread_mutex_trylock` will never wait to acquire a mutex but throw an error code immediately if unable to acquire the lock\n",
    "    - `pthread_mutex_timedlock` allows the programmer to specify the maximum waiting time \n",
    "        - If the mutex cannot be acquired within that time the procedure returns an error code \n",
    "\n",
    "\n",
    "- Types of mutexes in the POSIX standard\n",
    "    - `PTHREAD MUTEX DEFAULT` \n",
    "        - If a thread tries to lock a mutex that it already holds or unlocks one it does not, all bets are off as to what will happen. \n",
    "        - The programmer has the responsibility for this never happening \n",
    "        - Different POSIX system may behave differently\n",
    "    - `PTHREAD MUTEX ERROR CHECK`\n",
    "        - If a thread tries to lock a mutex that it alreadyholds, or unlock a mutex that it doesn’t hold, the operation returns an error code. \n",
    "    - `PTHREAD MUTEX NORMAL`\n",
    "        - If a thread tries to lock a mutex that it already holds it goes into a deadlock situation waiting for itself to unlock the thread\n",
    "        - If it tries to unlock a lock it does not hold all bets are off and each POSIX-compliant system is free to respond however it likes.\n",
    "    - `PTHREAD MUTEX RECURSIVE` \n",
    "        - If a thread tries to unlock a mutex it does not hold it returns an error code\n",
    "        - When a thread tries to lock a mutex it already holds it simple increments a counter and it is allowed to proceed, then when it unlocks it decrements the counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitors\n",
    "- In object oriented programming the mutex can be used in a very rigidly structured way:\n",
    "    - All state variables within an object should be kept private and only accessible by the code within that object\n",
    "    - Every object should contain a mutex as an additional field \n",
    "    - Every method should start by locking that object's mutex and end by unlocking it before returning\n",
    "    \n",
    "    \n",
    "- When the mutex rules are applied it will be impossible for two thread to race an objects state\n",
    "    - An programming language can follow the mutex rules are the programmer can apply them manually \n",
    "    - An object that automatically follows the mutex rules are called a **monitor**.\n",
    "        - e.g. in pascal using the keyword `monitor` or in java using the keyword `synchronized,`at the beginning of every non-private method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underlying Mechanisms for Mutexes\n",
    "- All modern processor  architectures has at least one instruction that can be used to both change the contents of a memory location and get information about the previous contents of the location\n",
    "    - These instructions are executed atomically\n",
    "    - One of them is called the `exchange` operation, which atomically swaps the contents of a register with the contents of a memory location\n",
    "  \n",
    "  \n",
    "- **The basic spinlock**\n",
    "    - It can be represented as a memory location that contains 1 if the mutex is unlocked and 0 if the mutex is locked\n",
    "    - The unlock operation can be trivial: to unlock a mutex just store 1 into it\n",
    "    - The lock operation uses the atomically exchange operation where it swaps a 0 with 0 until it gets a 1\n",
    "        - Psuedo code\n",
    "```\n",
    "        to lock mutex:\n",
    "            let temp = 0\n",
    "            repeat\n",
    "                atomically exchange temp and mutex\n",
    "            until temp = 1\n",
    "```\n",
    "    - Due to cache coherence the basic spin lock is very inefficient when two threads are waiting at the same time\n",
    "        - To avoid this reads can be used instead an then when the mutex becomes unlock they try to grab it and is refered to as the **Cache-conscious spinlock**\n",
    "    - A mutex that uses busy waiting is called a **spinlock**\n",
    "\n",
    "\n",
    "- **The queuing lock**\n",
    "    - Notifies the operating system that it needs to wait \n",
    "    - Notifying that the thread needs to wait requires some overhead \n",
    "        - Therefore the relative efficiency of spinlocks and queuing locks depends on the time the lock waits\n",
    "    - Used for cases where a thread might hold a mutex a long time\n",
    "    - Has three components \n",
    "        - A memory location used to record the mutexs state, 1 for unlocked or 0 for locked\n",
    "        - A list of threads waiting to acquire the mutex\n",
    "            - This list allows the scheduler to place the threads in a waiting state \n",
    "        - A cache-conscious spinlock, used to protect against races in operations on the mutex ifself \n",
    "    - The locked mutex is passed from one thread to another without being unlocked "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Synchronization Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounded Buffers\n",
    "- Often two threads are linked together in a processing **pipeline**\n",
    "    - Where one thread (**producer**) produces output used by other thread (**consumer**)\n",
    "    - Can be done using a a intermediate storage area called a **buffer**, where the producer places results and the consumer retrieve the result\n",
    "    - If the consumer tries to retrieve a value from and empty buffer it needs to wait for the producer to catch up\n",
    "    - If using a limited sized buffer (**bounded buffer**) the producer needs to wait if it gets to far ahead\n",
    "    - Found in the piping feature in UNIX: `ls | tr a-z A-Z`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader/Writers Locks \n",
    "- A **readers/writers lock** is much like a mutex excepts that when a thread lcosk the lock, it specifies whether it is planning to do any writing to the protected data structure or only reading\n",
    "    - The lock operating like a mutex waits until the lock can be acquired\n",
    "    - Any number of readers can hold the lock at the same time\n",
    "    - Has a higher overhead than a mutex since a mutex is simpler\n",
    "    - To avoid starvation of waiting writers some versions of reader/writers locks make new readers wait until after the waiting writers\n",
    "    \n",
    "    \n",
    "- The POSIX standard includes readers/writers locks\n",
    "    - Used with procedures such as `pthread_rwlock_init`, `pthread_rwlock_rdlock`, `pthread_rwlock_wrlock`, and `pthread_rwlock_unlock`\n",
    "    - The POSIX standard leaves it up to each individual system how to priorities new readers versus waiting writers\n",
    "    - The POSIX standard also includes a more specialized form of readers/writers locks specifically associated with files\n",
    "        - In the POSIX standard, file locks are available through the complex `fcnt` procedure\n",
    "        - Most UNIX-family OSs also provide a simpler interface, `flock`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barriers \n",
    "- **Barriers** are most commonly used in programs that do large-scale numerical calculations for scientific or engineering applications\n",
    "    - May also be used in other application as long as there is a requirement for all threads in a group to finish one phase of the computation before any of the moves on to the next phase\n",
    "- When a barrier is created, the programming specifies how many threads will be sharing it \n",
    "    - Each of the threads completes the first phase of the computations and then invokes the barrier's wait operation\n",
    "    - When the last thread invokes the wait operation the wait operation immediately returns \n",
    "    - When the all the threads are done with the first phase they proceed to the second phase and the barrier is used again and for the remaining phases\n",
    "    - Barriers are provided as part of POSIX and other widely available APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Variables\n",
    "- **Condition variables** can be used to help a thread wait until circumstances are appropriate for it to proceed\n",
    "    - It works in partnership with monitors or with mutexes used in the style of monitors\n",
    "    - There are two basic operations on a condition variable `wait` and `notify`\n",
    "    - A thread that finds circumstances that are not to its liking invokes the wait command and goes to sleep until another thread invokes the notify command \n",
    "    - In Java each object has a single condition variable automatically associated with it \n",
    "        - An objects `wait` method wait on the objects condition variable\n",
    "        - The `notifyAll` method wakes up all the threads waiting \n",
    "    - When calling the `wait` the thread releases the lock so anther threads can use it \n",
    "    - The waiting needs to be done inside a while loop to ensure that the invariant is true\n",
    "    \n",
    "    \n",
    "- The POSIX API allows multiple condition variable per mutex\n",
    "    - They are initialized with `pthread_cond_init` independent of any particular mutex\n",
    "    - The mutex is passed as an argument to `pthread_cond_wait` with the condition variable being waited on\n",
    "    - The operations corresponding to `notify` and `notifyAll` are called `pthread_cond_signal` and `pthread_cond_broadcast` without holding corresponding mutex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semaphores\n",
    "- **Semaphores** are another synchronization mechanism with the same generality as monitors with condition variables\n",
    "    - They are less natural, resulting in more error-prone code \n",
    "    - The applications where they are more natural e.g. bounded buffers they result in very succinct clear code \n",
    "    - Used before monitors\n",
    "    - Available in Java as the class `Semaphore` from the package `java.util.concurrent`\n",
    "    \n",
    "\n",
    "- A semaphore is essentialy an unsigned integer variable where only three operations are allowed:\n",
    "    - At the time the semaphore is created, it may be initialized to any nonnegative integer of the programmers choice\n",
    "    - It may be increased by 1\n",
    "        - The operation is called either `release`, `up` or `V`\n",
    "    - It may be decreased by 1\n",
    "        - The operation is called either `acquire`, `down` or `P`\n",
    "        - The thread performing an `acquire` operation waits if the value is 0. \n",
    "        - Only once another thread has performed a `release` operation to make the value positive does the waiting thread continue with its acquire operation \n",
    "\n",
    "\n",
    "- Semaphore can be used as mutexes\n",
    "    - It should be initialized to one\n",
    "    - `acquire` is used as the ocking operation and `release` as unlocking\n",
    "    - can result it some nasty behavior if unlocked 2 times\n",
    "\n",
    "\n",
    "- Semaphores can be used for keeping track of the available quantity of some resource, such as free spaces or data values in a bounded buffer \n",
    "    - Whenever a thread creates a unit of the resource it increases the semaphores\n",
    "    - Whenever a thread wants to consume a unit of resource it first does an `acquire` on the semaphore\n",
    "    - It can be used e.g. on a `BoundedBuffer`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadlocks\n",
    "- A **deadlock** exists whenever there is a cycle of threads, each waiting for some resource held by the next under the following defining conditions\n",
    "    1. Threads hold resources exclusively (\"mutual exclusions\") \n",
    "    2. Threads hold some resources while waiting for additional ones (\"wait for\")\n",
    "    3. Resources cannot be removed from threads forcibly (\"No preemption\")\n",
    "    4. Threads wait in a circular chain such that each thread holds resources that are requested by the next thread in the chain\n",
    "- Deadlocks are quite rare even if measures are taken to avoid them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Ordering (Deadlock prevention)\n",
    "- The ideal way to cope with deadlocks is preventing them from happening\n",
    "    - **Deadlock prevention** aims to ensure that at least one of the four defining conditions is not satisfied\n",
    "- One way of deadlock prevention targets the circular wait situation which is characterized by condition 4 by imposing a linear order in which resources need to be locked \n",
    "    - Ordered by memory location \n",
    "    - Can only be done if the locks needed are known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex Post Facto (Deadlock detection)\n",
    "- To detect a deadlock information about who is waiting for whom is needed \n",
    "    - Can be done by keeping mutex records not just whether it is locked or unlocked but also which thread it is held by if any and which threads are waiting for it\n",
    "\n",
    "\n",
    "- With information about who is waiting for whom a **resource allocation graph** can be constructed\n",
    "    - Threads are represented as squares.\n",
    "    - Mutexs are represented as circles\n",
    "    - The arrows shod which mutex each thread is waiting to acquire and which thread each mutex is currently held by\n",
    "    - If a graph has a cycle it means that the system is deadlocked\n",
    "    \n",
    "    \n",
    "- A system can test for deadlocks periodically or when a thread has waited an unreasonable long time for a lock\n",
    "    - To test for a deadlock the system uses a standard graph algorithm to check whether the resource allocation graph contains a cycle \n",
    "    - Since a mutex out-degree can be greater than one a simple graph search can be used\n",
    "\n",
    "\n",
    "- When a deadlock is detected, one of the deadlocked threads must be forcible terminated or rolled back to an earlier state to free up mutexes \n",
    "    - Ex Post Facto is not commonly used in general purpose operating system because of this, but can be useful in a database system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immediate Deadlock Detection\n",
    "- **Immediate deadlock detection** is intervening at the very moment when the system would otherwise deadlock\n",
    "    - As long as the deadlock is not allowed to occur the resource allocation graph will remain acyclic\n",
    "\n",
    "\n",
    "- Each time a thread tries to lock a mutex, the system can act as follows\n",
    "    - If the mutex is unlocked, lock it and add an edge from the mutex to the thread, to indicate that the thread holds the lock\n",
    "    - If the mutex is locked follow the chain of edges from it until the chain ends is the end of the chain the same as the thread trying to lock the mutex\n",
    "        - If not add an edge showing that the thread is waiting for the mutex and put the thread into a waiting state\n",
    "        - If the end of the chain is the same thread, adding the extra edge would complete the cycle \n",
    "            - Do not add the edge and do not put the thread into a waiting state\n",
    "            - Return an error code from the lock request or throw an exception indicate that the mutex could not be locked because an deadlock would have results\n",
    "\n",
    "\n",
    "- When a possible deadlock is detected the program release all locks it currently holds and restart \n",
    "    - The chance of repeating the response can be reduced by sleeping \n",
    "    \n",
    "- Used in `fcntl` in Linux and Mac OS for file locks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Interaction of Synchronization with Scheduling\n",
    "- Synchronization and scheduling interact with one another \n",
    "    - Since the scheduler controls which runnable thread runs on each processor and synchronization actions preformed by the running thread controls which threads are runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority Inversion \n",
    "- If threads of different priority levels share mutexes or other block synchronization primitives, some minor violations of priority ordering are inevitable\n",
    "    - A low priority having a mutex while a high priority one waits for it is generally no a big violation because programmers ensure that threads does not holds mutexes for very long\n",
    "\n",
    "\n",
    "- **Priority Inversion** occurs when a low priority holds a mutex that a high priority thread needs and then when then medium priority thread runs in stead keeping the high-priority from running because the low priority one cannot run\n",
    "    - A solution is to avoid fixed priority scheduling and use a decay one instead\n",
    "    - The genuine solution is **priority inheritance**.\n",
    "        - Any thread that is waiting for a mutex temporarily lends its priority to the thread that holds the mutex\n",
    "        - A thread that holds mutexes runs with the highest priority among its own priority and those priorities it has been lend by the other threads waiting for the mutex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Convoy Phenomenon \n",
    "- The queue of threads in a popular mutex is names the **convoy**\n",
    "    - This causes threads which holds the mutex to runs for a time slice and then stop when trying to acquire the mutex again\n",
    "    - Creates a long queue where each thread in turn moving from the front of the mutex through a brief period of execution and back to the rear of the queue \n",
    "    - This causes to problems two problems\n",
    "        - The context switching rate goes up. I\n",
    "            - Instead of one context switch pr time slice there is one per attempt to acquire the popular mutex\n",
    "            - The overhead of all tge context  switches will affect the throughput\n",
    "        - The scheduler's policy for choosing which thread to run is subverted \n",
    "            - This can be avoided by handling the mutex wait queue in priority order the same way as the run queue \n",
    "    - It can be avoided by making all the threads runnable and unlocking the mutex\n",
    "    - The POSIX stanard API for mutexes requires that one or the other of the two prioritization-preserving approaches to be takes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonblocking Synchronization\n",
    "- To an unblocking version of a set function can use the compare-and-set instruction meets this need by doing the following two things atomically (Java example: `AtomicReference` in `java.util.concurrent.atomic` package) .:\n",
    "    1. The instruction determines whether a variable contains a specified value and reports the answer\n",
    "    2. The instruction sets the variable to a new value, but only if the answer to the preceding question was yes\n",
    "\n",
    "- It can be done until successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "- LANs, IP and TCP are often called **layers**\n",
    "    - They constitute the Link layer, the Internet work layer and Transport layer respectively\n",
    "    - Together with the application layer they form the **\"four-layer model\"** for networks\n",
    "\n",
    "\n",
    "- The LAN layer is in charge of actual delivering a packets, using LAN supplied addresses \n",
    "    - Is often subdivided into the physical layer dealing with the e.g. radio signals and mechanisms involved and above it and abstracted logical LAN layer that describes the digital non-analog operations on packages \n",
    "    - If divided gives us a five-layer model\n",
    "![network_layers.png](img/network_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Rate, Throughput and Bandwidth\n",
    "- Any network connection e.g. the LAN layer has a **data rate**\n",
    "    - The rate which bits are transmitted\n",
    "    - The data rate can vary with time in some LANs e.g. Wi-Fi\n",
    "- **Throughput** refers to the overall effective transmission rate\n",
    "    - Taking into account into account things like transmission overhead, protocol ineffectiveness and perhaps even competing traffic \n",
    "    - Is generally measured a network layer than data rate\n",
    "- **Bandwidth** can refer to either data rate or throughput\n",
    "    - Mostly used for data rate (in the book)\n",
    "- The term **goodput** is used to refer to the \"application layer throughput\" when talking about TCP \n",
    "    - The amount of usable data being delivered to the receiving application \n",
    "- Data rates are generally calculated in kilobits per second (Kbps) or megabits per second (Mbps); the use of lowercase \"b\" denotes bits\n",
    "    - In the context of data rates, a kilobit is $10^3$ bits (not $2^{10}$ ) and a megabit is $10^6$ bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packets\n",
    "- Packets are a modest-sized buffer, transmitted as a unit through some shared set of links \n",
    "    - Packets needs to be prefixed with a **header** containing delivery information\n",
    "    - The the common case known as **datagram forwarding**, the header contains a destination **address**\n",
    "    - Headers in networks using **virtual-circuit** forward contain an indentifier for the connection\n",
    "    - Almost all networking today are packet based \n",
    "\n",
    "- At the LAN layer, packets can be viewed as the imposition of a buffer (and addressing) structure on top of low-level serial lines\n",
    "    - Additional layers then impose additional structure\n",
    "    - Packets are often referred to as **frames** at the LAN layer and as **segments** at the Transport layer\n",
    "    \n",
    "- The max packet size supported by a given LAN is an intrinsic attribute of that LAN\n",
    "    - Ethernet allows a maximum of 1500 bytes of data\n",
    "- Each layer adds its own header\n",
    "\n",
    "\n",
    "- In datagram-forwarding networks the appropriate header will contain the address of the destination and perhaps other delivery information\n",
    "    - Internal nodes of the network called **routers** or **switches** try to ensure that the packet are delivered to the requested destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datagram Forwarding \n",
    "- In the datagram-forwarding model of packets delivery, packet headers contain a destination address. \n",
    "    - It is up to the intervening switches or routers to look at this address and get the packets to the correct destination\n",
    "    - It used both by Ethernet switches and by IP routers l\n",
    "    \n",
    "    \n",
    "- Delivering is achieved by providing each switch with a forwarding table of $\\langle$destination,next_hop$\\rangle$ pairs. \n",
    "    - When a packet arrived the switch looks up the destination address in its forwarding table and finds the **next_hop** information: \n",
    "        - the immediate-neighbor address to which the packet should be forwarded to bring it closer to the destination\n",
    "    - The next_hop value in the forwarding table is a single entry; each switch is only responsible for a single step in the switch bath \n",
    "    - The destination entries in the forwarding table do not have to correspond exactly with the packet destination address\n",
    "        - They do for ethernet datagram forwarding \n",
    "        - In IP routing, the table destination correspond to **prefixes** of IP addresses \n",
    "    - The fundamental requirement is that a switch can determine the next hop using its forwarding table and destination address in the arriving packet\n",
    "    - Is also called **stateless** forwarding \n",
    "    - IP routers commonly as a **default** entry matching any nonlocal IP addresses \n",
    "    \n",
    "    \n",
    "- The fundamental alternative is **virtual circuts**\n",
    "    - Each router maintains state about each connection passing through it,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethernet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Mbps Classic Ethernet\n",
    "- The Ethernet originally consisted of a long cable and when a station transmitted data went everywhere along the cable \n",
    "    - Is known as a **broadcast bus** \n",
    "    - All packets were on the physical layer, broadcast onto a shared medium and could be seen by all other nodes \n",
    "    - The **network interface** took care of the details of transmitting, receiving and deciding which packet should be forwarded to the host via CPU interrupt\n",
    "        - Made it appear logically as peer-to-peer\n",
    "        \n",
    "- If to stations transmitted as the same time both signals would **collide** and fail as a result\n",
    "    - In order to minimize collision loss, each station would implement the following\n",
    "        1. Before the transmission wait for the line to become quite \n",
    "        2. While transmitting continually monitor the line for signs that a collision has occurred; if a collision is detected cease transmitting \n",
    "        3. If a collision occurs, use backoff-and-retransmit strategy \n",
    "    - The collision avoidance properties can be summarized with the **CSMA/CD** acronym: Carrier Sense, Multiple Access, Collision Detect.\n",
    "\n",
    "\n",
    "- Errors can occur\n",
    "    - when packets have bits flipped or garbled by electrical noise on the cable\n",
    "        - Ethernet package contain a 32-bit CRC error-detecting code to detect bit errors\n",
    "    - when the package is be misaddressed by the sending host or if they arrive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethernet Packet Format\n",
    "- The format of a typical Ethernet packet, which is still used for newer, faster Ethernets:\n",
    "![ethernet_format](img/ethernet_format.png)\n",
    "    - The destination and source addresses are 48-bit quantities\n",
    "    - The type is 16-bits\n",
    "        - Identifies the higher protocol layer \n",
    "    - The data length is a variable up to a maximum of 1500 bytes  \n",
    "    - The CRC checksum is 32-bits \n",
    "        - Added by the Ethernet hardware, never by host software \n",
    "    - There are also a preamble, which is a block of 1 bits followed by a 0, in front of the packet for synchronization \n",
    "    - Each ethernet card has it own hardware address used for identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethernet Multicast\n",
    "- Another category of Ethernet addresses are **multicast**\n",
    "    - Used to transmit a set of stations\n",
    "    - The lowest order bit of the first byte of the address indicates whether an address is physical or multicast\n",
    "    - To receive packets address to a given multicast address the host must inform the network interface that it wishes to do so \n",
    "        - Once done any arriving packets addressed to that multicast address are forwarded to the host\n",
    "    - The set of subscribers to a given multicast address is called a **multicast group** \n",
    "    - If several host subscribe to the same multicast address they each receive a copy of each multicast packet transmitted\n",
    "    - If switches are involved they normally forward multicast packages or broadcast packages on all outbound links \n",
    "\n",
    "\n",
    "- All the cases in which a network interface forwards a received packet up to its attached host:\n",
    "    - if the destination address of the received packet matches the physical address of an interface\n",
    "    - if the destination address of the received package is a broadcast address\n",
    "    - if the interface is in promiscuous mode (receive all packages)\n",
    "    - if the destination address of the received packet is a multicast address and the host has told the network interface to accept packets sent to that multicast address\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethernet Address Internal Structure\n",
    "- The second-to-lowers-order bit of a physical Ethernet address indicates whether the address is believed to be globally unique or if its only locally unique \n",
    "    - Known as the **Universal/Local** bit \n",
    "    - For real Ethernet physical address, the multicast and universal/local bits of the first byte should be 0\n",
    "    - Global Ethernet IDs are assigned to the physical Ethernet card by the manufacture \n",
    "        - The first three bytes serve indicate the manufacture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LAN Layer\n",
    "- The LAN layer, \n",
    "    - at its upper end, supplies to the network layer a  mechanisms for addressing a package a sending it from one station to another\n",
    "    - at its lower end handles interactions with the physical layer\n",
    "    - covers packet addressing, delivery and receipt, forwarding, error detection, collision detection and collision-related retransmission attempts\n",
    "    - is divided into the **media access control**, or MAC, sublayer and a higher **logical link control** or LLC sublayer for higher-level flow-control functions that today have moved largely to the transport layer\n",
    "        - The MAC layer is oftest used since it has the most frequently used functions \n",
    "        - LAN layer addresses are often called MAC addresses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Slot Time and Collisions\n",
    "- The **diameter** of an Ethernet is the maximum distance between any pair of stations\n",
    "    - The maximum allowed diameter, measured in bits is limited to 232, which makes the round-trip-time 464 bits\n",
    "    - If a station involved in a collision discovers a it, it transmit a special **jam signal** of up to 48 bits \n",
    "    - The time to send 512 bits is the **slot time** of an Ethernet\n",
    "        - Often described in bit times but in in conventional time units the slot time is 51.2 µsec.\n",
    "    - If a station has transmitted for one slot time it is said to **acquired** the network\n",
    "        - No collision can occur since any other station had has enough time to find out that the first station is transmitting \n",
    "    - The Ethernet has a **minimum package size** equal to the slot time\n",
    "        - A station transmitted that package are assured that is a collision were to occur, the sender would detect it and apply the retransmission algorithm\n",
    "    - The Ethernet has a **maximum** packet size, of 1500 bytes\n",
    "        - It is primarily for the sake of fairness "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Backoff Algorithm\n",
    "- Whenever there is a collision the Exponential Backoff Algorithm operating at the MAC layer is used to determine when each station will retry its transmission  \n",
    "- The full Ethernet transmission algorithm\n",
    "    1. Listen before transmitting (\"carrier detect\")\n",
    "    2. If line is busy, wait for sender to stop and then wait an additional 9.6 microseconds (96 bits).\n",
    "        - One consequence of this is that there is always a 96-bit gap between packets, so packets do not run together.\n",
    "    3. Transmit while simultaneously monitoring for collisions\n",
    "    4. If a collision does occur, send the jam signal and choose a backoff time as follows\n",
    "        - For transmission $N$, $1\\leq N \\leq 10$ choose $k$ randomly with $0 \\leq k < 2^N$. Wait $k$ time slots times, check if line is idle, waiting if necessary for someone else to finish and then retry step 3. For $10 \\leq N \\leq 15$ choose k randomly with $0 \\leq k < 2^10$ \n",
    "    5. If we reach $N = 16$ give up \n",
    "\n",
    "\n",
    "- A problem that can occur when using the exponential Backoff Algorithm is the **Capture effect**\n",
    "    - Is a potential lack of fairness\n",
    "    - Happens when one device is lucky a gets the line most when the other is trying to send the first package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSMA persistence\n",
    "- A carrier-sense/multiple-access transmission strategy is said to be **nonpersistent** if when the line is busy it waits a randomly selected time\n",
    "- A strategy is said to be **p-persistent** if, after waiting for the line to clear, the sender sends with probability $p\\leq 1$\n",
    "- The ethernet uses 1-persistent \n",
    "    - A consequence of this is that if more than one device are waiting for the line to clear a collision is certain \n",
    "    - Ethernet handles gracefully a resulting collision via the usual exponential backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethernet Learning Algorithm\n",
    "- The solution for a switch to act as a drop-in replacement for a hub is to start out with an empty forwarding table and the incremently build the table to a learning process\n",
    "    - If a switch does not have an entry for a particular destination, it will **fall back to flooding**\n",
    "        - It will forward the packet out every interface other than the one which it arrived\n",
    "    - A switch learns address locations as follows\n",
    "        - For each interface, the switch maintains a table of physical (MAC) addresses that have appeared as source addresses in packets arriving via that interface\n",
    "        - When a package arrives on interface $I$ with source address $S$ and destination unicast address $D$, the switch enters $\\langle S, I \\rangle$ into its forwarding table\n",
    "    - To deliver a packet, the switch also looks up the destination $D$ in the forwarding table.\n",
    "        - If an entry $\\langle D,J \\rangle$ with $J \\ne I$ exists the switch **forwards** the packet out interface $J$\n",
    "        - If an entry $\\langle D,J \\rangle$ with $J = I$ exists the packet does not get forwarded at all\n",
    "        - If there is no entry for $D$ the switch must flood the package out all interface $J$ with $J\\ne I$ \n",
    "    - After a while the fallback-to-flooding alternative is needed less and less often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanning Tree Algorithm and Redudancy \n",
    "- Used to avoid loops \n",
    "- The switch with the lowest id is the root\n",
    "- To create the spanning three it disable all the interfaces not following the following rules:\n",
    "    1. It enables the port via which it reaches the root\n",
    "    2. It enables any of its ports that further-out switches use to reach the root\n",
    "    3. If a remaining port connects to a segment to which other “segment-neighbor” switches connect as well, the port is enabled if the switch has the minimum cost to the root among those segment-neighbors, or, if a tie, the smallest ID among those neighbors, or, if two ports are tied, the port with the smaller ID.\n",
    "    4. If a port has no directly connected switch-neighbors, it presumably connects to a host or segment, and the port is enabled. Rules 1 and 2 construct the spanning tree; if S3 reaches the root via S2, then Rule 1 makes sure S3’s port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Delay \n",
    "- There are several contributing sources to the packet delay\n",
    "    - On LAN the most significant is **bandwidth delay**\n",
    "        - The time needed for a sender to get onto the wire \n",
    "        - This is simply the packet size divided by the bandwidth\n",
    "    - There is also **propagation delay**\n",
    "        - This relates to the propagation of the bits at the speed of light\n",
    "        - This delay is the distance divided by the speed of light \n",
    "    - The introduction of switches leads to **store-and-forward delay**,\n",
    "        - The time reading the packet before any of it can be retransmitted \n",
    "    - A switch may also introduce **queuing delay** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection\n",
    "- The basis strategy for error detection is to add some extra bits formally known as **error-detection code**, that will allow the receiver to determine is the packet has been corrupted in transit \n",
    "    - A corrupted package will be discarded by the receiver \n",
    "    - Packet errors generally fall into two categories: \n",
    "        - low-frequency bit errors due to things like cosmic rays, and interference errors, typically generated by nearby electrical equipment. \n",
    "        - Errors of the latter type generally occur in bursts, with multiple bad bits per packet. Occasionally, a malfunctioning network device will introduce bursty errors as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IP Version 4 \n",
    "- IP has a better scalability than LAN\n",
    "- The IP network service should act like a giant LAN\n",
    "- To support package size higher than what LAN allows the IP protocol supports **fragmentation**\n",
    "    - Breaks a large package into units that it can transport successfully "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IPv4 Header\n",
    "- The IPv4 header needs to contain the following information:\n",
    "    - destination and source address \n",
    "    - indication of ipv4 vs ipv6\n",
    "    - a Time To Live (TTL) value to prevent infinite routing loops \n",
    "    - a field indicating that comes next in the packet (e.g. TCP v UDP)\n",
    "    - fields supporting fragmentation and reassembly.\n",
    "\n",
    "\n",
    "- The header is organized as a series of 32-bit words as follows :\n",
    "![ipv4_header](img/ipv4_header.png)\n",
    "    - The **Version** field is, for IPv4, the number 4: 0100\n",
    "    - The **IHL** field represents the total IPv4 Header Length in 32-bit words\n",
    "        - an IPv4 Header can thus be at most 15 words long\n",
    "        - The base header  takes up five words, so the IPv¤ Options can consist of at most ten words.\n",
    "    - The **Dofferential Services** (DS) field is used by the Differentiated Services suite to specify preferential handling for designated packets\n",
    "        - e.g. those involved in VoIP or other real-time protocols\n",
    "    - The **Explicit Congestion Notification** bits  are there to allow router experiencing congestion to mark packets\n",
    "        - This indicates to the sender that the transmission rate should be reduced\n",
    "    - The **Total Length** field is present because an IPv¤ packet may be smaller than the minimum LAN packet size or larger than thewe maximum\n",
    "        - The IPv4 packet length, in other words, cannot be inferred from the LAN- level packet size. \n",
    "        - Because the Total Length field is 16 bits, the maximum IPv4 packet size is 2 16 bytes.\n",
    "    -  The **Time-to-Live** (TTL) field is decremented by 1 at each router and used to avoid loops\n",
    "        - If it reaches 0, the packet is discard\n",
    "        - A typical initial value is 64\n",
    "            - It must be larger than the total number of hops in the path \n",
    "        - In most cases a  value of 32 would work \n",
    "    - The **Protocol** field contains a value to indentify the contents of the packet body such as\n",
    "        - 1: an ICMP package \n",
    "        - 4: an encapsulated IPv4 packet\n",
    "    - The **Header Checksum** field is the \"Internet checksum\" applied to the header only\n",
    "        - It purpose is to allow discarding packets with corrupted headers \n",
    "        - When the TTL value is decremented the router must update this, and this can be done algebraically by adding a 1 in the correct place to compensate\n",
    "        - Also update when the packet header is rewritten by a NAT router\n",
    "    - The **Source** and **Destination Address** fields contain the IPv4 addresses \n",
    "        - Only updated by NAT firewalls\n",
    "        - The source address can be changed to allow for IP **spoofing**\n",
    "    - **IPv4 options**\n",
    "        - The **Record Route** option in which routers are to insert their own IPv4 address into the IPv4 header option area\n",
    "        - The **Timestamp** option where intermediate routers are requested to mark their address and a local time stamp +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfaces\n",
    "- IP addresses are, strictly speaking, assigned not to hosts or nodes, but to **interfaces**\n",
    "- Each comnputer likely also has a **loopback** interface, which provides a way to deliver IP packets to other processes on the same machine\n",
    "    - Often named local host and resolves to the IPv4 loopback address 127.0.0.1\n",
    "    - Loopback delivery avoids the the need to use the LAN at all\n",
    "    - On unix-based machines the loopback interface represents a genuine logical interface, commonly named `lo`. \n",
    "- When VPN connections are created each end of the logical connection terminates at a virtual interface\n",
    "    - The virtual interfaces appear to the systems involved, to be attached to a point-to-point link that leads to the other end\n",
    "- When a computer hosts a virtual machine there is almost always a virtual network to connect host and the virtual machine\n",
    "    - The host uses a virtual interface and may act as a NAT router or as an Ethernet switch \n",
    "- A host with multiple \"real\" network interfaces is often said to be **multihomed**\n",
    "    - Many computers has both a Ethernet interfasce and a Wi-Fi interface which can be used a the same time with different addresses\n",
    "- It is possible to assign multiple IP addresses to a single interface\n",
    "    - e.g. to allow two IP networks to share a single physical LAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Addresses\n",
    "- A few IPv4 addresses represent special cases\n",
    "    - The standard loopback address is 127.0.0.1,\n",
    "        - Any host beginning with 127 can serve as loopback host\n",
    "    - **Private addresses** are addresses only intended for internal use\n",
    "        - If a packet shows up on a non-private router containing a private address it should be dropped\n",
    "        - There are three standard private address blocks that have been defined \n",
    "            - `10.0.0.0/8`\n",
    "            - `172.16.0.0/12`\n",
    "            - `192.168.0.0/16`\n",
    "    - **Broadcast addresses** are a special form of addresses that are intended to be used in conjunction with the LAN-layer broadcast\n",
    "        - The most common forms are\n",
    "            - *\"Broadcast to this network\"* consisting of all 1 bits \n",
    "            - *\"Broadcast to network D\"* consisting of D's network address followed by all 1-bits for the host address \n",
    "                - If trying to broadcast to a remote network the odds are that some router will refuse it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fragmentation\n",
    "- There are two potential fragmentation strategies \n",
    "    - **per-link** fragmentation and reassembly where the reassembly is done at the opposite end of the link \n",
    "    - **path** fragmentation and reassembly where the reassemble is done in the opposite end of the link\n",
    "        - is used by IPv4\n",
    "    \n",
    "\n",
    "- An IPv4 sender is supposed to use a different value for the **INDENT** field for different packages \n",
    "    - When a IPv4 datagram is fragmented it keeps the same INDENT field\n",
    "\n",
    "\n",
    "- After fragmentation the **Fragment Offset** field marks the start position of the data portion of the fragment within the original IPv4 packet.\n",
    "    - It can be numbered up to $2^{16}$ \n",
    "    - The three fragment bits in the header are the following\n",
    "        - The first bit is reserved and must be 0 \n",
    "        - The second bit is the **Don’t Fragment** bit and if set the router should not fragment the package and drop it instead\n",
    "        - The third bit is set to 1 for all fragments except the final one \n",
    "            - tells the receiver where the fragments stop \n",
    "            \n",
    "            \n",
    "- The receiver must take the fragments and reassemble the package \n",
    "    - The package may not arrive in order \n",
    "    - The reassembler must identify when arriving packages are part of the same package \n",
    "    - Fragments are considered to belong to the same packet  if they have the same IDENT field, source and destination addresses and same protocol. \n",
    "    - If packages arrive that are part of a new fragmented packet a buffer is allocated\n",
    "        - A bitmap is allocated to keep track of arrived bits\n",
    "        - As subsequent fragments arrived they are placed in the buffer and the approiate be placed in the proper buffer in the proper position. \n",
    "        - If the bitmap shows that all packets has arrived the packet is sent on up as a complete IPv4 packet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Classless IP Delivery Algorithm\n",
    "- To decide if a IPv4 address D is **local** or **nonlocal** the host or router involved we do f0r each network address B/k assigned to one of the host’s interfaces a comparison of the first k bits of B and D; that is, we ask if D matches B/k.\n",
    "    - If one these comparisons yield a match delivery is **local**\n",
    "        - The host delivers the package via the LAN connected to the corresponding interface\n",
    "        - That means looking up the LAN address of the destination and if applicable sending the packet to that destination via the interface\n",
    "    - If there is no match delivery is **nonlocal**\n",
    "        - The host passes $D$ to the `lookup()` routine of the forwarding table and sends it to the associated next_hop\n",
    "        - It is know up to `lookup()` to split D into D$_{\\text{net}}$ and D$_{\\text{host}}$ this split cannot be made outside lookup\n",
    "\n",
    "\n",
    "- The forwarding table is abstractly a set of network addresses, with lengths, on the form B/k with an associated next_hop for each\n",
    "    - The `lookup()` routine will in principle compare the D with each table entry B/k looking for a match\n",
    "    header to store a net/host division point, and furthermore different routers along the path may use different\n",
    "    - Routers receive the prefix length /k for a destination B/k as part of the process by which they receive $\\langle$destination,next_hopy pairs$\\rangle$ \n",
    "    - When there are multiple matches in one table the **longest-match** rule is used to pick the best match\n",
    "    - There may also be a default entry at the table which is typically 0.0.0.0/0 which will match everything \n",
    "    - Routers may also be configured to pass quality of service to the lookup table to best determine a path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPv4 Subnets\n",
    "- A larger network can be divided into subnets \n",
    "    - Subnets introduce **hierarchical routing**: first we route to the primary network then inside that site we route to the subnet and finally the last hop delivers to the host \n",
    "    - To implemented subnets the site's IPv4 network is divided into some combination of physical LANS and assign each a subnet address\n",
    "    - A subnet address is an IPv4 network address B/k such that:\n",
    "        - The address B/k is within the site: the first n bits of B are the same as A/n’s\n",
    "        - B/k extends A/n: $k \\geq n$\n",
    "- To be able for host within a subnet to send something to a host of another subnet a **subnet mask** is used\n",
    "    - A subnet mask is created for each subnet address B/k, consisting of k 1-bits followed by enough 0-bits to make a total of 32.\n",
    "    - We need to make sure that every host and router knows the subnet address for everyone of its interfaces \n",
    "    - Hosts usually find their subnet mask the same way they find their IP address\n",
    "- The host and routers apply the IP delivery algorithm, with the condition that, if a subnet mask for an interface is present, then the subnet mask is used to determine the number of address bits raters than the Class A/B/C mechanism\n",
    "    - Done by comparing D&M and B&M, where D is the destination, the subnet address is B and the mask is M, if they are  equal the packet is local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Address Translation\n",
    "- NAT has the abilityu to multiplex and arbitrarily large number of individual hosts behind a single IPv4 address (or small number of addresses\n",
    "    - The basis idea is that, instead of assigning each ghost at a site a public visible IPv4 address, just one address is assigned to a special device known as a NAT router (often called router)\n",
    "    - One side of the NAT router connects to the internet the other connects to the site's internal network \n",
    "    - Hosts on the internal network are assigned private IP addresses typically on the form 192.168.x.y or 10.x.y.z\n",
    "    - Connection to internal host from the outside world are banned \n",
    "    - When an internal machine wants to connect to the outside the NAT router intercepts the connection and forwards the connection's packets after rewriting the source address to make it seem like they came from the NAT routers own IP\n",
    "        - When a remote machine responds the NAT router remembers the connection (stored in a special forwarding table) and forward the data to the correct internal host rewriting the destination address field of the incoming packets\n",
    "        - The NAT forwarding table also includes ports numbers \n",
    "    - The NAT route improves security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Resolution Protocol: ARP \n",
    "- ARP is used when a host or router A finds that the destination IP address D=D$_\\text{IP}$ mactches the network address of one of its interfaces, it is to deliver the packet via LAN \n",
    "- The basic idea of ARP is that the host A sends out a broadcast ARP query or \"who has D$_\\text{IP}$\" request, which includes A's own IPv4 and LAN addresses \n",
    "    - All hosts on the lan receive this message.\n",
    "    - The host for whom the message is indended, D, will recognize that it should reply and whill return an ARP reply or \"is-at\" message containing D$_\\text{LAN}$\n",
    "    - Because the original request contained A$_\\text{LAN}$, D's response can be sent directly to A \n",
    "    \n",
    "\n",
    "- All host maintain an **ARP cache** consisting of $\\langle$IPv4. LAN$\\rangle$ address pairs for other hosts on the network\n",
    "    - After an exchange the involved hosts and/or routers puts the other into their cache\n",
    "    - ARP-cache entries eventually expire and a ARP query is send out about this entry\n",
    "    - This cuts down the total amount of broadcast trafficjj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARP Finer Points\n",
    "- Most host implement **self-ARP** or **gratuitous ARP** on startup\n",
    "    - When a station A starts up it sends out an ARP query for itself: *\"who has a\"*\n",
    "    - To things are gained from this\n",
    "        - All stations which had A are now updated with A's most current A$_\\text{LAN}$ address \n",
    "        - If an answer is received, then presumably some other host on the network has the same IPv4 address as A.\n",
    "\n",
    "\n",
    "- ARP can be used for **duplicate address detection** though it does not often work well \n",
    "    - Often only a single self-ARP query is sent, and if a reply is received then frequently the only response is to log an error message; \n",
    "    - The host may even continue using the duplicate address\n",
    "\n",
    "\n",
    "- There have been defined improved mechanism known as **Address Conflict Detection** (ACD)\n",
    "    - A host using ACD sends out three ARP queries for its new IPv4 address, spaced over a few seconds.\n",
    "    - It leaves the ARP field for the sender's IPv4 address filled with zeroes. \n",
    "    - This means that any other host with that IPv4 address in its cache will ignore the packet, rather than update its cache. \n",
    "    - If the original host receives no replies, it then sends out two more ARP queries for its new address,\n",
    "        - This time with the ARP field for the sender's IPv4 address filled in with the new address\n",
    "        - This is the stage at which other hosts on the network will make any necessary cache updates. \n",
    "    - Finally, ACD requires that hosts that do detect a duplicate address must discontinue using it. It is also possible for other stations to answer an ARP query on behalf of the actual destination \n",
    "    \n",
    "    \n",
    "- It is also possible for other stations to answer an ARP query on half of the actual destination D\n",
    "    - This is called **proxy ARP** \n",
    "- It is important to have time out time to avoid the network being flooded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Host Configuration Protocol (DHCP)\n",
    "- DHCP is the most common mechanism byt which hosts are assigned their IPv4 addresses\n",
    "- DHCP invovles a host, at startup, broadcasting a query containing its own LAN address and having a server reply telling the host what IPv4 address is assigned to it \n",
    "    - Also called Reverse ARP \n",
    "\n",
    "\n",
    "- The DNCP response message is likely to carry, piggypacked onto it, several other essential startup options\n",
    "    - Unlike the IPv4 address the additional network parameters does not usually depend on the specific host\n",
    "    - A typical DHCP message includes the following\n",
    "        - IPv4 address\n",
    "        - subnet mask\n",
    "        - default router\n",
    "        - DNS Server\n",
    "    - The options are called **minimal network configuration**\n",
    "        - Hosts cannot function properly without these \n",
    "        \n",
    "        \n",
    "- The DHCP server has a range of IPv4 addresses to hand out\n",
    "    - It maintains a database of which IPv4 address has been assigned to which LAN address.\n",
    "    - Reservations can either be permanent or dynamic\n",
    "    - If reservations are dynamic, hosts typically renew their DHCP reservation periodically-\n",
    "    \n",
    "\n",
    "- The typical home/small-office \"router\" is a NAT router coupled with an Ethernet switch, and usually also coupled with a Wi-Fi access point and a DHCP server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internet Control Message Protocol\n",
    "- The Internet Control Message Protocol (ICMP) is a protocol for send IP-layer error and status messages\n",
    "    - ICMP is, like IP, **host-to-host** and they are never delivered to a specific port even if they are sent in response to an error related to a specific port\n",
    "\n",
    "\n",
    "- ICMP messages are identified by an 8-bit **type** field, followed by an 8-bit subtype, or **code**, the most common ICMP types with subtypes listed in the description\n",
    "![ICMP_types](img/ICMP_types.png)\n",
    "- The Echo and Timestamp formats are queries, sent by one host to another. \n",
    "\n",
    "- Most of them are all error messages, sent by a router to the sender of the offending packet. \n",
    "    - Error-message formats contain the IP header and next 8 bytes of the packet in question; the 8 bytes will contain the TCP or UDP port numbers. \n",
    "    - Redirect and Router Solicitation messages are informational, but follow the error-message format. \n",
    "    - Query formats contain a 16-bit Query Identifier, assigned by the query sender and echoed back by the query responder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing-Update Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance-Vector Routing-Update Algorithm\n",
    "- Distance-vector is the simplest routing-update algorithm used by the Routing Information Protocol\n",
    "    - Routers identify their router neighbors and add a thrid column to their forwarding tables representing the total **cost** for delivery to the corresponding destination\n",
    "        - Through some sort of neighbor-discovery mechanism \n",
    "        - The cost are the distance\n",
    "    - Forwarding table entries are of the form $\\langle$destination, next_hop, cost$\\rangle$\n",
    "    - Cost are administratively assigned to each link\n",
    "    - The algorithm calculates the total cost as the sum of the link cost along the path\n",
    "        - If a cost of 1 is assigned to each link it is called the hopcount metric\n",
    "        - Link cost can also reflect each linkøs bandwidth, or delay\n",
    "    - Each router reports the $\\langle$destination, cost$\\rangle$ portion of its table to its neighboring router at regular intervals \n",
    "        - These table portions are the vectors\n",
    "    - Each router monitors its continued connectivity to each neighbor\n",
    "        - If a neighbor becomes unreachable its reachability cost is set to infinity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update rules\n",
    "- Let $A$ be a router receiving a report $\\langle D, c_D \\rangle$ from neighbor $N$ at cost $c_N$, this means that $A$ can reach $D$ via $N$ with cost $c=c_D+c_N$. $A$ updates its own table according to these rules\n",
    "    1. **New destination**: D is previously unknown destination. $A$ adds $\\langle D. M, c \\rangle$ to its forwarding table \n",
    "    2. **Lower cost**: D is a known destination with entry $\\langle D,M,c_{old} \\rangle$. but the new total cost $c$ is less than $c_{old}$.$A$ switches to the cheaper route, updating its entry for D to $\\langle D,N,c \\rangle$\n",
    "        - It is possible that $M=N$\n",
    "        - If $c=c_{old}$ A ignores the new report\n",
    "    3. **Mext_hop increase:** $A$ has an existing $\\langle D,N,c_{old} \\rangle$ and the new total cost $c$ is greater than $c_{old}$ . $A$ updates its entry for $D$ to $\\langle D,N,c \\rangle$ \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance-Vector Slow-Convergence Problem\n",
    "- The **Distance-Vector Slow-Convergence Problem** happens when a link breaks and another neighbors sends a packets before the link where the it broken \n",
    "    - Results in an infinite loop since the to neighbors sends the packet to each other for ever \n",
    "    \n",
    "- Fixes to the Distance Vector Slow-Convergence Problem\n",
    "    - The simplest fix to this problem is to use a small value for infinity \n",
    "        - No path can be longer than this value \n",
    "    - Under **split horizon** if $A$ uses $N$ as its next_hop for destination $D$  then $A$ simply does not report to $N$ that it can reach $D$\n",
    "        - When preparing a report to $N$ it first deletes all entries that have $N$ as next_hop\n",
    "        - Can prevent all linear routing loops but cannot prevent all non linear\n",
    "        - Can also use **poison reverse** where a cost of $\\infty$ is report instead of deleting them\n",
    "    - Under **Triggered Updates** any router should report immediately to its neighbors whenever it detects any change for the worse\n",
    "    - **Hold down** dictates that the receiver does not use new alternative routes for a period of time following the discovery of unreachability\n",
    "        - This gives time for the bad news to arrive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract sliding windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Reliable Transport: Stop-and-Wait\n",
    "- `Data[N]jj` represents the Nth data packes\n",
    "    - is acknowledge by `ACK[N]`\n",
    "\n",
    "- In the **stop-and-wait** version of retransmit-on-timeout, the sender sends only one outstanding packet at a time\n",
    "    - If there is no response the packet may be retransmitted\n",
    "    - The sender does not send `Data[N+1]` until it has received `ACK[N]`\n",
    "    - Each side has only one packet in play at a time\n",
    "    - If the `ACK[N]` is lost the sender sends a duplicate `Data[N]` and the receiver has implemented a **retransmit-on-duplicate**\n",
    "    - Each site must implement a **retransmit-on-timeout**\n",
    "        - Otherwise a lost packet leads to a deadlock\n",
    "    - The receiver must either implement retransmit-on-timeout or **retransmit-on-duplicate**\n",
    "    - To avoid the **Sorcerer’s Apprentice Bug** were the double amount of packages is send only one side should only implement one strategy\n",
    "        - Usually the sender only implements the **retransmit-on-timeout**\n",
    "        \n",
    "\n",
    "- Stop-and-wait provides a simple form of **flow control** to prevent data from arriving at the receiver faster than it can be handled\n",
    "    - The stop-and-wait mechanism will prevent data from arriving too fast if the time to process a received package is less than one RTT\n",
    "    - If the processing time is slightly larger than RTT, all the receiver has to do is wait to send `ACK[N]` until `Data[N]` not only has arrived but also been processed and the receiver is ready\n",
    "    - To show that data has been received but the receiver is has not processed it yet the `ACK`$_{\\text{WAIT}}$[N] is used and when ready the ACK$_\\text{GO}$[N] is used\n",
    "        - Creates a new problem where the sender is waiting for the ACK$_\\text{GO}$[N] but it is lost, which can be solved by the receiver using the retransmit-on-timeout in that period.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Windows\n",
    "- Sliding Windows want to improve on the efficiency of stop and wait by allowing the sender to send multiple packages at once \n",
    "    - `ACK[N]` cannot be sent until `Data[K]` has arrived for all $K \\leq N$ \n",
    "    - The sender picks a **window size**, winsize, which is the amount of packets the sender is allowed to send before waiting for an `ACK` \n",
    "        - The sender keeps a state variable **last_ACKed** which represents the last packets which it has received an ACK from the other end (initially 0 if packets are one indexed)\n",
    "    - At any instant, the sender may send packets numbered last_ACKed +1 through last_ACKed+winsize\n",
    "        - This range is known as the **window** \n",
    "    - If `ACK[N]` arrives with N>last_ACKed, the windows slides forward\n",
    "        - We set lasst_ACKed = N\n",
    "    - If there is no packet reordering and no packets losses the windows will slides forward in one units at a time\n",
    "\n",
    "\n",
    "- The bandwidth $\\times$ RTT product is generally the optimum value for the window size\n",
    "    - If the sender chooses a winsize larger than this, the RTT grows due to queuing delays\n",
    "    - The sender is often more interested in bandwidth RTT$_\\text{noLoad}$\n",
    "        - Sometimes referred to as the **transit capacity** of the route\n",
    "        - A window size smaller than this means underutilization of the network\n",
    "\n",
    "\n",
    "- Sliding windows can work pretty well with the receiver assuming winsize=1\n",
    "    - Like the sender, the receiver will also maintain the state variable last_ACKede\n",
    "    - At any instant the receiver is ready to receive Data[last_ACKed+1] through Data[last_ACKed+winsize].\n",
    "\n",
    "\n",
    "- If no response is received the sender only sends the first lost package\n",
    "    - When a full timeout has occurred the sliding windows process has to ground in a halt, which is called **pipeline drain**    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDP \n",
    "- UDP header\n",
    "![udp_header](img/udp_header.png)\n",
    "- UDP is fairly basic \n",
    "    - The two features it adds beyond IP are **port numbers** and a **checksum** \n",
    "    - The port numbers are what makes UDP into a real transport protocol with them a process can not connect as an individual server process\n",
    "        - Rather than simply a host\n",
    "    - UDP is unreliable in that there is no UDP-layer attempt at timeouts timeouts, acknowledgment and retransmission\n",
    "        - Applications written for UDP must implement these \n",
    "    - As with TCP, a UDP pair $\\langle$host,port$\\rangle$ is known as a socket\n",
    "    - UDP is **unconnected** or **stateless**\n",
    "        - If an application has opened a port on a host, any other host on the Internet may deliver packets to that  $\\langle$host,port$\\rangle$ socket without preliminary negotiation.\n",
    "    - UDP packets use a 16-bit Internet **checksum** on the data\n",
    "        - Can be disabled and set to an all 0-bits value\n",
    "        - It covers the UDP header, the UDP data and also a *\"pseudo-IP header\"* that includes the source and destination IP addresses. \n",
    "        - If a NAT router rewrites an IP address or port the checksum must be updated\n",
    "    - UDP packets can be dropped due to queue overflows either at an intervening route or at the receiving host \n",
    "    - UDP is popular for local transport\n",
    "        - Is typically used as a transport basis for RPC\n",
    "    - UDP is well suited for *\"request-reply\"* sematics\n",
    "        - Uses less overhead than TCP\n",
    "    - UDP is popular for **real-time** transport\n",
    "        - Because of the **loss tolerance**\n",
    "        - RTP is built on top of UDP rather than TCP (common for VoIP calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivial File Transport Protocol (TFTP)\n",
    "- TFTP supports file transfers in both directions\n",
    "    - Does not support a mechanism for authentication\n",
    "    - Uses stop-and-wait and often a fixed timeout interval \n",
    "    - Typically confined to internal use within a LAN \n",
    "\n",
    "\n",
    "- TFTP has five packet types\n",
    "    - Read ReQuest, RRQ containing the filename and a text/binary indication\n",
    "    - Write Request, WRQ\n",
    "    - Data, containing a 16-bit clock number and up to 512 bytes of data\n",
    "    - ACK, containing a 16-bit block number\n",
    "    - Error, for certain designated errors \n",
    "        - All errors other than \"Unknown Transfer ID\" are cause for sender termination\n",
    "\n",
    "\n",
    "- Data block numbering begins at 1\n",
    "    - The packet with the Nth block of data is denoted as Data[N] and acknowledgements are Ack[N]\n",
    "    - All blocks o data contain 512 bytes except the final block\n",
    "        - The final block is identified by containing less than 512 bytes of data\n",
    "        - If the file size was divisible by 512, the final block will contain 0 bytes of data\n",
    "    - TFTP numbers are 16 bits in length, and are not allowed to wrap around\n",
    "    \n",
    "\n",
    "- The TFTP server listens on UDP port 69 for arriving RRQ packets \n",
    "    - For each RRQ requesting a valid file, TFTP server implementations almost always create a separate process (or thread) to handle the transfer\n",
    "        - That child process will obtain an entirely new UDP port, which will be used for all further interaction with the client for this particular transfer\n",
    "\n",
    "\n",
    "- In the absence of packet loss or other errors, TFTP file requests typically proceed as follows:\n",
    "    1. The client sends a RRQ to server port 69.\n",
    "    2. The server creates a child process, which obtains a new port, s_port, from the operating system.\n",
    "    3. The server child process sends Data[1] from s_port.\n",
    "        - Refered to as **latching on** to that port\n",
    "    4. The client receives Data[1], and thus learns the value of s_port. The client will verify that each future  Data[N] arrives from this same port.\n",
    "    5. The client sends ACK[1] (and all future ACKs) to the server’s s_port.\n",
    "    6. The server child process sends Data[2], etc, each time waiting for the client ACK[N] before sending   Data[N+1].\n",
    "    7. The transfer process stops when the server sends its final block, of size less than 512 bytes, and the   client sends the corresponding ACK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Transport "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Transport Issues\n",
    "- Some issues regarding any transport strategy\n",
    "    - Old Duplicate Packets\n",
    "        - Happens when a package is lost due to delay, a duplicate one is send and then a new connection mistakes it\n",
    "        - A packet from a previous instance of the connection is called an **external** old duplicate\n",
    "            - Two separate instances of a connection between the same socket addresses are sometimes known as **incarnations** of the connection, particularly in the context of TCP.\n",
    "            - The TFTP defense to this is that both endpoints try and choose a different port for each separate transfer\n",
    "        - **Internal** old duplicate could happen if the data numbers was allowed to wrap around\n",
    "    - Lost Final ACK\n",
    "        - One cannot be certain that the final ACK is received because no ack is send to the receiver\n",
    "        - It is addressed by TFTP by recommending that the receiver enter into a **DALLY** state when it has to sent the final ACK\n",
    "            - In this state the receiver responds only to deuplicates of the final DATA packet and retransmit the final ACK \n",
    "            - The dally state will expire after an interval which should be at least twicer the senders timeout interval\n",
    "            - Reduces greatly the possibility of the last ACK being lost\n",
    "    - Duplicated Connection Request\n",
    "        - It happens when a connection cancels a read transfers and starts another one \n",
    "            - Then the new transfer can get the old once packets by mistake\n",
    "        - It can be solved by the receiver changing port number\n",
    "    - Reboot\n",
    "        - TFTP has to take into account that one side may reboot between messages from the other side \n",
    "        - It is problem with huge importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCP\n",
    "- The **End-to-End** Principle states that transport issues are the responsibility of the endpoints in questions\n",
    "- The TCP header:\n",
    "![tcp_header](img/tcp_header.png)\n",
    "    - The checksum covers the TCP header, the TCP data and an IP \"pseudo header\" the includes the source and destination IP addresses\n",
    "        - Must be updated by a NAT router that modifies any header values\n",
    "    - The **sequence** and **acknowledgement** numbers are for numbering the data at the byte level\n",
    "        - This allows TCP to send 1024 blocks of data incrementing the sequence number by 1024 between successive packets or send 1-byte telnet packets, incrementing the sequence number by 1 each time\n",
    "        - There is no distinction between DATA and ACK packets\n",
    "            - All packets carrying data from A to B also carry the most current acknowledgement of data sent from B to A. \n",
    "            - Many TCP applications are largely unidirectional \n",
    "        - It is traditional to refer to the data portion of TCP packets as **segments** \n",
    "        - The value of the sequence number is the position of the first byte of the packet in the data stream or the position of where the first byte would be in case no data was sent\n",
    "        - The value of the acknowledgment number represents the byte position for the next byte expected\n",
    "        - The sequence and acknowledgment numbers, as sent, represent these relative values plus an Initial Sequence Number, or ISN, that is fixed for the lifetime of the connection. \n",
    "            - Each direction of a connection has its own ISN\n",
    "        - The TCP acknowledgements are **cumulative**\n",
    "            - It acknowledging receipt of all data byte numbered less than N where N is the acknowledgment number\n",
    "    - The TCP header defines the following flag bits\n",
    "        - **SYN**: for SYNchronize, marks packets that are part of the new connection handshake\n",
    "        - **ACK**: indicates that the header ACcknowledgment field is valid, that is all but the first packet\n",
    "        - **FIN**: for FINish, marks packets involved in the connection closing \n",
    "        - **PSH**: for PuSH, marks *\"non-full\"* packets that should be delivered promptly at the far end\n",
    "        - **RST**: for ReSet, indicates various error conditions\n",
    "        - **URG**: for URGent, part of a now-seldom-used mechanism for high-priority data\n",
    "        - **CWR** and **ECE**: part of the Explicit Congestion Notification mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCP Connection Establishment \n",
    "- TCP connections are established via an exchange known as the **three-way handshake**, A is the client and B is the LISTENing server then the handshake goes as follows\n",
    "    - A sends B a packet with the SYN bit set (a SYN packet)\n",
    "    - B responds with a SYN packet of its own, the ACK bit is now also set\n",
    "    - A responds to B's SYN with its own ACK\n",
    "\n",
    "\n",
    "- Normally a three way handshake is triggered by an application's request to connect\n",
    "    - Data can only be send after the handshake completes\n",
    "    - It is vulnerable to an attack known as **SYN flooding** \n",
    "        - The attacker sends a large number of SYN packets to a server B\n",
    "        - For each arriving resource B must allocate resources and B's resources may face exhaustion\n",
    "        \n",
    "- To **close** the connection, a superficially similar exchange involving FIN packets may occur\n",
    "    - A sends B a packet with the FIN bit set (a FIN packet), announcing that it has finished sending data\n",
    "    - B sends A an ACK of the FIN\n",
    "    - B may continue to send additional data to A\n",
    "    - When B is also ready to cease sending, it sends its own FIN to A\n",
    "    - A sends B an ACK of the FIN; this is the final packet in the exchange\n",
    "\n",
    "\n",
    "- When closing a connection it is important to use `shutdown` instead of `close`\n",
    "    - `close` just closes the connection and does not listen for further data\n",
    "    - If the non closed part tries to send data the closed one might send a `rst` which means that all data sent is lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIMEWAIT\n",
    "- The TIMEWAIT state is entered by whichever side initiates the connection close\n",
    "    - In the event of a simultaneous close both sides enter TIMEWAIT \n",
    "    - It is to last for a time $2 \\ \\times$ MSL\n",
    "        - MSL is an agreed-upon value for the maximum lifetime on the Internet of an IP packet\n",
    "        - Traditionally 60 seconds but modern 30 seconds\n",
    "    - One function is to solve the external-old-duplicates problem\n",
    "        - Requires that enough time has passed for old duplicates to disappear \n",
    "    - A second function of TIMEWAIT is to address the lost-final-ACK problem\n",
    "        - TIMEWAIT only blocks reconnections for which both sides reuse the same port they used beforej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCP state diagram \n",
    "- The following is a **state diagram** for TCP\n",
    "![tcp_state](img/tcp_state.png)\n",
    "    - The blue arrows indicate the sequence of state transitions typically followed by the server\n",
    "    - The brown arrows represent the client\n",
    "    - Arrows are labeled with **event/action**\n",
    "    - The ESTABLISHED state and the states below it are sometimes called the **synchronized** states\n",
    "        - Since both sides have confirmed each others ISN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Web and HTTP\n",
    "- A webpage consists of **objects**\n",
    "    - A **object** is a file \n",
    "- HTTP uses TCP as its underlying transport protocol\n",
    "    - The HTTP client first initiates a TCP connection\n",
    "    - The client sends HTTP request messages into its socket interface and receives HTTP response messages from its socket interface. \n",
    "    - The server receives request messages from its socket interface and \n",
    "    - HTTP is said to a **stateless** protocols because thea server does not store and state on the different clients\n",
    "- A **non-persistent connection** is where each request/response pair is send over separate TCP connections\n",
    "- A **persistent connection** is where each request/response pair is send over the same TCP connection\n",
    "    - Used by the default mode in HTTP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP request message format\n",
    "- There are two different types of HTTP messages, request messages and response messages\n",
    "- Example of a typical HTTP request message\n",
    "```\n",
    "    GET /somedir/page.html HTTP/1.1\n",
    "    Host: www.someschool.edu\n",
    "    Connection: close\n",
    "    User-agent: Mozilla/5.0\n",
    "    Accept-language: fr\n",
    "```\n",
    "    - The first line of an HTTP request message is called the **request line** \n",
    "        - It has three fields: the message field, the URL field and HTTP version field\n",
    "        - The `HEAD` method is the same as the `GET` but it leaves out the body\n",
    "    - The subsequent lines are called **header lines**\n",
    "        - The header line starting with `Host:` specifies where the host lives \n",
    "        - By supplying the `Connection: close` the client tells the server that it doesn't want to bother with a persistent connection \n",
    "        - The `User-agent:` line what browser type is making the request \n",
    "        - The `Accept-language:` tells the server that it want the french version of the site\n",
    "\n",
    "![http_request_header_format](img/http_request_header_format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP Response Message\n",
    "- Example of HTTP response message\n",
    "```\n",
    "    HTTP/1.1 200 OK\n",
    "    Connection: close\n",
    "    Date: Tue, 09 Aug 2011 15:44:04 GMT\n",
    "    Server: Apache/2.2.3 (CentOS)\n",
    "    Last-Modified: Tue, 09 Aug 2011 15:11:03 GMT\n",
    "    Content-Length: 6821\n",
    "    Content-Type: text/html\n",
    "    \n",
    "    (data data....)\n",
    "```\n",
    "    - The first line is the status line which has three fields: the protocol version, the status code and the corresponding status message\n",
    "    - The other lines before the data is the header lines\n",
    "    - The `Connection: close` tells the client that it is going to close the connection after sending this message\n",
    "    - The `Date:` tells the client which and date the HTTP response message was created\n",
    "    - The `Server:` indicates which server has created the message\n",
    "    - The `Last-Modified:` indicates the time or date the object was created or modified\n",
    "    - The `Content-Length:` indicates the number of bytes being sent\n",
    "    - The `Content-Type:` indicates the objects type\n",
    "\n",
    "![http_response_header_format](img/http_response_header_format.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookies \n",
    "- Cookies allows sites to keep track of users\n",
    "- Example of a cookie header line when a new cookie is made: `Set-cookie: 1678`\n",
    "- Example of a cookie in a normal request: `Cookie: 1678`\n",
    "- A cookie consists of three components\n",
    "    1. A cookie header line in the HTTP response message\n",
    "    2. A cookie header line in the HTTP request message\n",
    "    3. A cookie file kept on the user's end system and managed by the user's browser \n",
    "    4. A back-end database at the Web site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-caching\n",
    "- A Web cache also called a proxy server is a network entity that satisfies HTTP requests on the behalf of an origin Web server. \n",
    "    - It has its own disk storage and keeps copies of recently requested objects in this storage.\n",
    "- The browser interacts with the net-cache in the following way\n",
    "    1. The browser establishes a TCP connection to the Web cache and sends an HTTP request for the object to the Web cache.\n",
    "    2. The Web cache checks to see if it has a copy of the object stored locally. \n",
    "        - If it does, the Web cache returns the object within an HTTP response message to the client browser.\n",
    "    3. If the Web cache does not have the object, the Web cache opens a TCP connection to the origin server. The Web cache then sends an HTTP request for the object into the cache-to-server TCP connection. \n",
    "        - After receiving this request, the origin server sends the object within an HTTP response to the Web cache.\n",
    "    4. When the Web cache receives the object, it stores a copy in its local storage and sends a copy, within an HTTP response message, to the client browser \n",
    "        - This is done over the existing TCP connection between the client browser and the Web cache.\n",
    "- A web cache is typically purchased and installed by an ISP \n",
    "- At web cache can substantually reduce an institution’s access link to the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The conditional GET\n",
    "- The mechanism **conditional GET** allows the web cache to verify that the objects are up to date\n",
    "- An HTTP request is a conditional GET if \n",
    "    1. The request message uses the GET message \n",
    "    2. The request message includes an `If-Modified-Since:` header line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTP\n",
    "- FTP is used to transfer files from a remote system to another system\n",
    "    - The user first provides the host name of the remote host\n",
    "        - This causes the FTP client to establish an TCP connection with the FTP server process on the remote host \n",
    "    - The users then provides the user identification and password\n",
    "        - This is send over TCP as a part of the FTP commands \n",
    "    - Once the server has authorized the user, the user copies one or more files stored in the local file system into the remote file system (or vice versa).\n",
    "    \n",
    "\n",
    "- FTP uses two parallel connection for to transfer a file a **control connection** and a **data connection**\n",
    "    - The control connection is used for sending control information between the two connections\n",
    "        - Information such as user identification, password, commands to change remote directory, and commands to \"put\" and \"get\" files. \n",
    "    - The data connection is used to actually send a file. \n",
    "    \n",
    "    \n",
    "- Since FTP uses a separate control connection, FTP is said to send its control information **out-of-band**\n",
    "    - For this reason, HTTP is said to send its control information **in-band**.\n",
    "    \n",
    "    \n",
    "- The client side of FTP  first initiates a control TCP connection with the server side (remote host) on server port number 21. \n",
    "    - The client side of FTP sends the user identification and password over this control connection\n",
    "    - The client also sends commands to change the directory through this connection\n",
    "    \n",
    "    \n",
    "- When the server side receives a command for a file transfer over the control connection, the server side initiates a TCP data connection to the  client side. \n",
    "    - FTP sends exactly one file over the data connection and then closes the data connection. \n",
    "    - If, during the same session, the user wants to transfer another file, the server opens another connection\n",
    "    \n",
    "    \n",
    "- Throughout a session FTP maintains a **state** about each user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTP commands and Replies \n",
    "- The commands, from client to server, and replies, from server to client, are sent across the control connection in 7-bit ASCII format. \n",
    "- Common FTP commands\n",
    "    - `USER username`: Used to send user identification to the server\n",
    "    - `PASS password`: Used to send the user password to the server\n",
    "    - `LIST`: Used to ask the server to send a list of all the files in the current directory \n",
    "        - The list of files are send over a new and non-persistent data-connection\n",
    "    - `RETR filename`: Used to retrieve (get) a file from the current directory on the remote server\n",
    "    - `STOR filename`: Used to store (put) a file into the current directory on the remote server\n",
    "\n",
    "\n",
    "- Each command is followed by a corresponding reply from the server to the client, which consists of a number with an optional message. Here are some examples\n",
    "    - `331 Username OK, password required`\n",
    "    - `125 Data Data connection already open; transfer starting`\n",
    "    - `425 Can't open data connection`\n",
    "    - `452 Error writing file`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronic Mail in the Internet\n",
    "- Internet mail has three major components: **user agents**, **mail servers** and **Simple Mail Transfer Protocol (SMTP)**\n",
    "- User agents allow the user to read, reply to, forward, save and compose message\n",
    "    - When the user is done composing an email the user agent sends the mail to the mail server, where the mail is placed in the mail servers outgoing queue\n",
    "    \n",
    "    \n",
    "- Mail servers form the core of the e-mail infrastructure. \n",
    "    - Each user has a mailbox located in one of the mail servers\n",
    "    - Each users mailbox manages and maintains the message that have been send to that person\n",
    "    - A message starts in the sender's user agent, then to the senders mail server, and then to the recipient mail server and is then deposited in the recipient's mailbox\n",
    "    - When a user wants to access messages in the mailbox, the mail server authenticates the User\n",
    "        - Done using usernames and passwords \n",
    "    - A mail server must deal with failures in other peoples mail servers\n",
    "    - If a mail server cannot deliver mail to another mail server it holds the message in a message queue and attempts again later\n",
    "        - Is often done every 30 minutes or so\n",
    "        - If there is no success after several days, the server removes the message and notifies the sender with e-mail address\n",
    "        \n",
    "        \n",
    "- SMTP is the principal application-layer protocol for Internet electronic mail. \n",
    "    - It TCP to transfer mail from the senders mail server to the recipient's mail server\n",
    "    - SMTP has two sides \n",
    "        1. A client site which executes on the sender's mail server\n",
    "        2. A server side which executes on the recipients mail server\n",
    "    - Both the client and the server side run on every mail server\n",
    "    - When a mail server sends mail to other servers it acts as SMTP client\n",
    "    - When a mail server receives mail from other servers it acts as SMTP server "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMTP\n",
    "- SMTP restricts the body (not just the headers) of all mail messages to simple 7-bit ASCII. \n",
    "- SMTP does not normally use intermediate mail servers for sending mail, instead a direct TCP connection is used\n",
    "- How SMTP transfers a message from a sending mail server to a receiving mail server\n",
    "    1. The client SMTP has TCP establish a connection to port 25 at the server SMTP\n",
    "        - If the server is down the client tries again later\n",
    "    2. The server and client perform some application-layer handshaking \n",
    "        - SMTP clients and servers introduce themselves before transferring information\n",
    "        - The SMTP client indicates the e-mail address of the sender and the e-mail of the recipient\n",
    "    3. The client sends the message\n",
    "        - The client repeats this process over the same TCP connection if it has other messages to send to the server\n",
    "        \n",
    "        \n",
    "- Example where `S` is server and `C` is client\n",
    "```\n",
    "    S: 220 hamburger.edu\n",
    "    C: HELO crepes.fr\n",
    "    S: 250 Hello crepes.fr, pleased to meet you\n",
    "    S: MAIL FROM: <alice@crepes.fr>\n",
    "    S: 250 alice@crepes.fr ... Sender ok\n",
    "    C: RCPT TO: <bob@hamburger.edu>\n",
    "    S: 250 bob@hamburger.edu ... Recipient ok\n",
    "    C: DATA\n",
    "    S: 354 Enter mail, end with \".\" on a line by itself\n",
    "    C: Do you like ketchup?\n",
    "    C: How about pickles?\n",
    "    C: .\n",
    "    S: 250 Message accepted for delivery\n",
    "    C: QUIT\n",
    "    S: 221 hamburger.edu closing connection\n",
    "```\n",
    "    - If more mails are send it begins each new mail with `MAIL FROM: crepes.fr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMTP header\n",
    "- Example of a SMTP header\n",
    "```\n",
    "    From: alice@crepes.fr\n",
    "    To: bob@hamburger.edu\n",
    "    Subject: Searching for the meaning of life.\n",
    "```\n",
    "    - Every header must have a `FROM` and `TO` line\n",
    "    - The `Subject:` line is optional\n",
    "    - The header lines are part of the mail message itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mail Access Protocols\n",
    "- SMTP cannot be used to access mails on the server since it uses a push operation \n",
    "- There are a number of popular mail access protocols, including Post Office Protocol—Version 3 (POP3), Internet Mail Access Protocol (IMAP), and HTTP. \n",
    "![mail_access](img/mail_access.png)\n",
    "\n",
    "- When the client it web based it sends and receives messages from the web server using the HTTP protocol "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POP3\n",
    "- POP3 is an extremely simple mail access protocol\n",
    "    - It has limited functionality\n",
    "    \n",
    "    \n",
    "- POP3 begins when the user agent open a TCP connection to the mail server on port 110\n",
    "- POP3 progresses through three phases: authorization, transaction, and update when a connection has been established\n",
    "    - **Authorization**: the user agent sends a username and a password to authenticate the user\n",
    "    - **Transaction**: the user agent retrieves messages and the user can\n",
    "        - mark messages for deletion\n",
    "        - remove deletion marks\n",
    "        - obtain mail statistics\n",
    "    - **Update**: the mail server deletes the messages that were marked for deletion\n",
    "        - Occurs after the client has issued the quit command which ends the session\n",
    "\n",
    "\n",
    "- In a POP3 transaction the user agent issues commands and the server responds with a reply to each command and there are two possible responses\n",
    "    - `+OK` which indicates that the previous command was fine \n",
    "        - It is sometimes followed by server-to-client data\n",
    "    - `-ERR` which indicates that something was wrong with the previous command\n",
    "        \n",
    "        \n",
    "- The authorization phase has two principal commands\n",
    "    - `user <username>`\n",
    "    - `pass <password>`\n",
    "\n",
    "\n",
    "- Example of authorization phase on mail server\n",
    "```\n",
    "telnet mailServer 110\n",
    "+OK POP3 server ready\n",
    "user bob\n",
    "+OK\n",
    "pass hungry\n",
    "+OK user successfully logged on\n",
    "```\n",
    "\n",
    "- During the transaction phase the user agent can often be configured to *\"download and delete\"* or *\"download and keep\"* \n",
    "    - In the download-and-delete mode, the user agent will issue the `list`, `retr`, and `dele` commands.\n",
    "        - Since the download-and-delete mode deletes the messages after reading them the user will not be able to view them on multiple computers\n",
    "    - In the download-and-keep mode the user agents keeps the messages on the server \n",
    " \n",
    " \n",
    "- Example transtion phase using *download and delete*\n",
    "```\n",
    "C: list\n",
    "S: 1 498\n",
    "S: 2 912\n",
    "S: .\n",
    "C: retr 1\n",
    "S: (blah blah ...\n",
    "S: .................\n",
    "S: ..........blah)\n",
    "S: .\n",
    "C: dele 1\n",
    "C: retr 2\n",
    "S: (blah blah ...\n",
    "S: .................\n",
    "S: ..........blah)\n",
    "S: .\n",
    "C: dele 2\n",
    "C: quit\n",
    "S: +OK POP3 server signing off\n",
    "```\n",
    "\n",
    "- POP3 only maintains the user state during the session "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAP\n",
    "- It is not possible to maintain a folder hierarchy on a remote server using POP3\n",
    "    - This and other problems is solved by the more complex IMAP \n",
    "    \n",
    "    \n",
    "- An IMAP server will associated each message with a folder \n",
    "    - When a message first arrives at the server it is associated with the recipients INBOX folder\n",
    "    - The recipient can move a message into a new, user-created folder, read the message, delete the message, and so on. \n",
    "    \n",
    "\n",
    "- The IMAP protocol provides commands to allow users to create folders move messages from one folder to another \n",
    "    - It  also provides commands that allow users to search remote folders for messages matching specific criteria\n",
    "\n",
    "\n",
    "- An IMAP server maintains user state information across IMAP sessions \n",
    "    - Such as the names of folders and which messages are associated with which folder\n",
    "    \n",
    "\n",
    "- IMAP has commands that permit the user agent to obtain component of messages\n",
    "    - A user can obtain the message header of the message or just one part of a multipart MIME message.\n",
    "    - It is useful for a low-bandwidth connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNS \n",
    "- The task of DNS is to translate hostnames to IP addresses \n",
    "    - DNS is a distributed database implemented in a hierarchy of DNS servers\n",
    "    - DNS is an application-layer protocol that allows host to query the distributed database\n",
    "\n",
    "\n",
    "- DNS servers are often UNIX machine running the Berkeley Internet Name Domain (BIND) software.\n",
    "    - The DNS protocol runs over UDP and uses port 53\n",
    "    - IT is commonly employed by other application-layer protocols such as HTTP, SWTPP, and FTP-to translate hostnames to IP addresses\n",
    "\n",
    "\n",
    "- DNS call to obtain the IP address of www.someschool.edu example\n",
    "    1. The same user machine runs the client side of the DNS application.\n",
    "    2. The browser extracts the hostname, www.someschool.edu, from the URL and passes the hostname to the client side of the DNS application.\n",
    "    3. The DNS client sends a query containing the hostname to a DNS server.\n",
    "    4. The DNS client eventually receives a reply, which includes the IP address for the hostname.\n",
    "    5. Once the browser receives the IP address from DNS, it can initiate a TCP connection to the HTTP server process located at port 80 at that IP address. \n",
    "    \n",
    "\n",
    "- DNS provides a few other important services in addition to translating hostnames to IP addresses:\n",
    "    - **Host aliasing**: A host with a complicated hostname can have one or more alias names. \n",
    "        - The original hostname is said to be the **canonical hostname**\n",
    "    - **Mail server aliasing**: DNS can be invoked by a mail application to obtain the canonical hostname for a supplied alias hostname as well as the IP address of the host. \n",
    "    - **Load distribution.** DNS is also used to perform load distribution among replicated servers, such as replicated web server\n",
    "        - For replicated servers a set of IP addresses are associated with one canonical hostname\n",
    "        - When clients make a DNS query for a name mapped to a set of addresses, the server responds with the entire set of IP addresses, but rotates the ordering of the addresses within each reply. \n",
    "        - DNS rotation is also used for e-mail so that multiple mail servers can have the same alias name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How DNS works\n",
    "- To translate a hostname to an IP address, the application invoke the client side of DNS \n",
    "    - It specifies what hostname needs to be translate\n",
    "        - On UNIX it is often the `getHostName()` function that is invoked\n",
    "    - All DNS query and reply messages are sent within UDP datagrams to port 53\n",
    "    - DNS in the user’s host takes over, sending a query message into the network.\n",
    "    - After a delay from milliseconds to seconds DNS in the user's host receives a DNS reply message that provides the desired mapping\n",
    "        - This is passed to the invoking application\n",
    "        \n",
    "        \n",
    "- In the perspective of the invoking application DNS is a black box  providing a simple, straightforward translation service\n",
    "    - DNS service is complex, consisting of a large number of DNS servers distributed around the globe and an application-layer protocol that specifies how the DNS servers and querying host communicate\n",
    "\n",
    "\n",
    "- Problems with a centralized design simple DNS server includes\n",
    "    - **A single point of failure**: If the DNS server crashed so does the entire Internet\n",
    "    - **Traffic volume**: A single DNS server would have to handle all DNS queries \n",
    "    - **Distant centralized database**: A single DNS server cannot be \"close to\" all the querying clients\n",
    "        - This can lead to significant delays\n",
    "    - **Maintenance**: A single DNS server would have to keep records for all Internet hosts\n",
    "        - It would not only have to be huge, but also have to be updated frequently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Distributed, Hierarchical Database\n",
    "- DNS uses a large number of servers to deal with the issue of scale\n",
    "    - They are organized in a hierarchical fashion and distributed around the world\n",
    "    - No a single server has all of the mapping for all the servers in the world\n",
    "    - Mappings are distributed across the DNS servers\n",
    "\n",
    "\n",
    "- There are three classes of DNS servers\n",
    "    - **Root DNS servers**: There are 13 root DNS servers on the internet\n",
    "        - Each server is a network of replicated servers for security and reliability purposes\n",
    "    - **Top-level-domain (TLD) servers**: These servers are responsible for top-level domains such as com, org, net, edu and gov, and all of the country top-level domains\n",
    "    - **Authoritative DNS servers**: Every organization with publicly accessible hosts on the Internet must provide publicly  accessible DNS records that map the names of those hosts to IP addresses.\n",
    "        - Such as Web servers and mail server\n",
    "        - An organization's authoritative DNS server houses these DNS records\n",
    "        - An organization can choose to implement its own authoritative DNS server to hold these records\n",
    "            - The the organization can pay to have these records stored in an authoritative DNS server of some service provider \n",
    "\n",
    "\n",
    "- A **local DNS server** does not strictly belong to the the hierarchy of servers but is nevertheless central to the DNS architecture.\n",
    "    - Each ISP has a local DNS server\n",
    "        - Such as a university, an academic department, an employee’s company, or a residential ISP\n",
    "        - Also called a default name server\n",
    "    - When a host connects to an ISP, the ISP provides the host with the IP addresses of one or more of its local DNS servers\n",
    "    - A host local DNS server is typically \"close to\" the host\n",
    "        - For an institutional ISP the DNS server may be on the same LAN\n",
    "        - For a residential ISP it is typically separated from the host by no more than a few routers\n",
    "    - When a host makes a DNS query, the query is sent to the local DNS server which acts a proxy\n",
    "        - It forwards the query into the DNS server hierarchy \n",
    "        \n",
    "   \n",
    "- A query can be iterative or recursive\n",
    "    - If it is **iterative**, the Root DNS servers and Top-level-domain servers gives the client an IP address of an Top-level-domain server and a Autoritative DNS server and it is the clients job to contact them\n",
    "    - If it is **recursive** the server does all the work contacting the correct servers and gives the correct IP address to the client\n",
    "    - DNS queries to a local DNS server are typically recursive and all others are iterative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNS caching\n",
    "- DNS caching is done each time a DNS server receives a DNS reply\n",
    "    - It can cache the mapping in its local memory\n",
    "    - If a hostname/IP address pair is cached in a DNS server and another query arrives to the same hostname the DNS server can provide the desired IP address\n",
    "    - DNS servers discard cached information after a period of time \n",
    "        - Often two days\n",
    "    \n",
    "    \n",
    "- A local DNS server can also cache the IP addresses of TLD servers, thereby allowing the local DNS server to bypass the root DNS servers in a query chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNS Records\n",
    "- The DNS servers that implement the DNS distributed database store resource records (RRs)\n",
    "    - Including RRs that provide hostname-to-IP address mappings\n",
    "    - Each DNS reply message carries one or more resource records\n",
    "\n",
    "\n",
    "- A resource records is a four-tuple that contains the following fields: `(Name, Value, Type, TTL)`\n",
    "    - TTL is the time to live of the resource record\n",
    "        - Determines when a resource should be removed from a cache\n",
    "    - The meaning of `Name` and `Value` depend on `Type`:\n",
    "        - If `Type=A` the `Name` is a hostname and `Value` is the IP address for the hostname\n",
    "            - Provides standard hostname-to-IP address mapping\n",
    "            - Example: `(relay1.bar.foo.com, 145.37.93.126, A)`\n",
    "        - If `Type=NS` the name is a domain and the `Value` is the host name of an authoritative DNS server that knows how to obtain the IP address for hosts in the domains\n",
    "            - Used to route DNS queries further along in the query chain\n",
    "            - Example: `(foo.com, dns.foo.com, NS)`\n",
    "        - If `Type=CNAME` the `Value` is a canonical hostname for the alias hostname Name\n",
    "            - This record can provide querying hosts the canonical name for a hostname.\n",
    "            - Example: `(foo.com, relay1.bar.foo.com, CNAME)`\n",
    "        - If `Type=MX`the Value is the canonical name of a mail server that has an alias hostname `Name`\n",
    "            - Example: `(foo.com, mail.bar.foo.com, MX)`\n",
    "            - They allow the hostnames of mail server to have simple aliases\n",
    "\n",
    "\n",
    "- If a DNS server is authoritative for a particular hostname, then the DNS server will contain a Type A record for the hostname.\n",
    "    - Even if it is not authoriative it may contain an A record in its cache\n",
    "    \n",
    "    \n",
    "- If a server is not authoritative for a hostname, then the server will contain a Type NS record for the domain that includes the hostname\n",
    "    - It will also contain a Type A record that provides the IP address of the DNS server in the Value field of the NS record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNS messages\n",
    "- There are only two kinds of DNS messages DNS query and reply messages\n",
    "    - They have the same format\n",
    "    \n",
    "\n",
    "- The semantics of the DNS messages are as follows\n",
    "![dns_message_format](img/dns_message_format.png)\n",
    "    - The first 12 bytes is the header header section, which has a number of fields\n",
    "        - The first field is a 16-bitt number that identifies the query\n",
    "            - This is copied into the reply message to a query, which allows the client to match received replies with send queries\n",
    "        - There are a number of flags in the flags field\n",
    "            - A 1-bit query/reply flags indicates whether the message is a query (0) or a reply (1)\n",
    "            - A 1-bit authoritative flag is set if the DNS server is an authoritative server for a queried name\n",
    "            - A 1-bit recursion-desired flag is set when a client desires that the DNS server perform recursion when it doesn't have the record\n",
    "                - It is set in a reply if the DNS server support recursion\n",
    "        - There are also four number fields, which indicates the number of occurrences of the four types of data following the header\n",
    "    - The question section contains information about the query that is being made and it includes\n",
    "        1. A name field that contains the name that is being query\n",
    "        2. A type field that indicates the type of question being asked about\n",
    "    - In a reply the answer section contains the resource records for the name that was originally queried \n",
    "        - A reply can return multiple RRs in the answer, since a hostname can have multiple IP addresses.\n",
    "    - The authority section contains records of other authoritative servers\n",
    "    - The additional section contains other helpful records\n",
    "        - For example, the answer field in a reply to an MX query contains a resource record providing the canonical hostname of a mail server. \n",
    "        - It contains a Type A record providing the IP address for the canonical hostname of the mail server. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "851px",
    "left": "0px",
    "right": "1708px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
